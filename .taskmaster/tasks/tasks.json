{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "프로젝트 초기 설정 및 의존성 설치",
        "description": "프로젝트의 기본 디렉토리 구조를 설정하고, 필요한 Python 의존성 라이브러리(watchdog, SQLAlchemy, requests, APScheduler, python-dotenv, PyYAML, psycopg2-binary)를 설치합니다.",
        "details": "프로젝트 루트에 `src/`, `config/`, `logs/`, `tests/` 등의 디렉토리를 생성합니다. `requirements.txt` 파일을 생성하고 다음 라이브러리를 명시합니다:\n- `watchdog==2.3.1` (파일 시스템 모니터링)\n- `SQLAlchemy==2.0.30` (ORM 및 DB 추상화)\n- `psycopg2-binary==2.9.9` (PostgreSQL 어댑터)\n- `requests==2.31.0` (HTTP 요청)\n- `APScheduler==3.10.4` (스케줄링)\n- `python-dotenv==1.0.1` (환경 변수 관리)\n- `PyYAML==6.0.1` (YAML 설정 파일 파싱)\n\n`venv`를 사용하여 가상 환경을 설정하고 `pip install -r requirements.txt` 명령으로 의존성을 설치합니다.",
        "testStrategy": "가상 환경이 성공적으로 생성되고 모든 의존성 라이브러리가 오류 없이 설치되었는지 확인합니다. `pip freeze` 명령으로 설치된 패키지 목록을 검증합니다.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "프로젝트 기본 디렉토리 구조 생성",
            "description": "프로젝트의 루트 디렉토리 내에 `src/`, `config/`, `logs/`, `tests/` 등의 핵심 하위 디렉토리를 생성합니다.",
            "dependencies": [],
            "details": "프로젝트 루트에 `src/`, `config/`, `logs/`, `tests/` 디렉토리를 생성합니다.",
            "status": "done",
            "testStrategy": "생성된 디렉토리들이 파일 시스템에 올바르게 존재하는지 확인합니다."
          },
          {
            "id": 2,
            "title": "Python 가상 환경 (venv) 설정",
            "description": "프로젝트의 격리된 개발 환경을 위해 Python `venv` 모듈을 사용하여 가상 환경을 생성합니다.",
            "dependencies": [
              "1.1"
            ],
            "details": "프로젝트 루트에 `python -m venv venv` 명령을 사용하여 `venv` 가상 환경을 생성합니다.",
            "status": "done",
            "testStrategy": "`venv/` 디렉토리가 생성되었는지 확인하고, 가상 환경 활성화 스크립트(예: `venv/bin/activate` 또는 `venv\\Scripts\\activate`)가 존재하는지 확인합니다."
          },
          {
            "id": 3,
            "title": "`requirements.txt` 파일 생성 및 라이브러리 명시",
            "description": "프로젝트에 필요한 모든 Python 의존성 라이브러리와 그 버전을 `requirements.txt` 파일에 명시합니다.",
            "dependencies": [
              "1.1"
            ],
            "details": "`requirements.txt` 파일을 생성하고 다음 라이브러리를 명시합니다: `watchdog==2.3.1`, `SQLAlchemy==2.0.30`, `psycopg2-binary==2.9.9`, `requests==2.31.0`, `APScheduler==3.10.4`, `python-dotenv==1.0.1`, `PyYAML==6.0.1`.",
            "status": "done",
            "testStrategy": "`requirements.txt` 파일이 프로젝트 루트에 생성되었는지, 그리고 명시된 모든 라이브러리와 버전이 정확하게 포함되어 있는지 파일 내용을 확인합니다."
          },
          {
            "id": 4,
            "title": "가상 환경 활성화 및 의존성 라이브러리 설치",
            "description": "생성된 가상 환경을 활성화하고, `requirements.txt`에 명시된 모든 Python 의존성 라이브러리를 `pip`를 사용하여 설치합니다.",
            "dependencies": [
              "1.2",
              "1.3"
            ],
            "details": "가상 환경을 활성화한 후 `pip install -r requirements.txt` 명령을 실행하여 의존성을 설치합니다.",
            "status": "done",
            "testStrategy": "`pip install -r requirements.txt` 명령 실행 시 오류가 발생하지 않는지 확인합니다."
          },
          {
            "id": 5,
            "title": "설치된 의존성 라이브러리 검증",
            "description": "모든 필수 의존성 라이브러리가 가상 환경에 올바른 버전으로 설치되었는지 확인합니다.",
            "dependencies": [
              "1.4"
            ],
            "details": "가상 환경이 활성화된 상태에서 `pip freeze` 명령을 실행하여 설치된 패키지 목록을 확인하고, `requirements.txt`에 명시된 모든 라이브러리가 올바른 버전으로 설치되었는지 검증합니다.",
            "status": "done",
            "testStrategy": "`pip freeze` 출력 결과에 `watchdog==2.3.1`, `SQLAlchemy==2.0.30`, `psycopg2-binary==2.9.9`, `requests==2.31.0`, `APScheduler==3.10.4`, `python-dotenv==1.0.1`, `PyYAML==6.0.1`이 모두 포함되어 있는지 확인합니다."
          }
        ]
      },
      {
        "id": 2,
        "title": "설정 관리 시스템 구현",
        "description": "시스템의 다양한 설정(모니터링 폴더 경로, API 엔드포인트, DB 연결 정보, 로그 레벨 등)을 관리하기 위한 설정 파일 구조를 정의하고 구현합니다. 환경 변수를 통한 민감 정보 관리도 포함합니다.",
        "details": "YAML 형식의 설정 파일(`config/settings.yaml`)을 사용하여 시스템 설정을 관리합니다. `python-dotenv`를 사용하여 `.env` 파일에서 민감한 정보(예: API 키, DB 비밀번호)를 로드합니다.\n\n`config/settings.py`:\n```python\nimport os\nimport yaml\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\ndef load_config(env='development'):\n    with open(f'config/settings.yaml', 'r', encoding='utf-8') as f:\n        config = yaml.safe_load(f)\n    \n    # 환경 변수 오버라이드\n    config['database']['host'] = os.getenv('DB_HOST', config['database']['host'])\n    config['api']['endpoint'] = os.getenv('API_ENDPOINT', config['api']['endpoint'])\n    # ... 기타 환경 변수 설정\n    return config\n\nCONFIG = load_config(os.getenv('APP_ENV', 'development'))\n```\n`config/settings.yaml` 예시:\n```yaml\nmonitor:\n  base_folders:\n    - /path/to/Sega_1\n    - /path/to/Sega_2\n    - /path/to/Sega_3\n  scan_interval_minutes: 1\n  image_extensions:\n    - .jpg\n    - .png\n\ndatabase:\n  type: sqlite # 또는 postgresql\n  sqlite_path: data/app.db\n  host: localhost\n  port: 5432\n  user: user\n  password: password\n  dbname: mydb\n\napi:\n  endpoint: http://211.231.137.111:18000/upload\n  timeout_seconds: 30\n  retry_attempts: 5\n  retry_delay_seconds: 5\n\nlogging:\n  level: INFO\n  file: logs/app.log\n  max_bytes: 10485760 # 10MB\n  backup_count: 5\n```",
        "testStrategy": "다양한 설정 값으로 `settings.yaml` 파일을 구성하고, `.env` 파일로 환경 변수를 오버라이드하여 올바르게 로드되는지 확인합니다. 존재하지 않는 설정에 접근 시 적절한 오류 처리가 되는지 확인합니다.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "YAML 설정 파일 구조 정의",
            "description": "시스템의 다양한 설정(모니터링 폴더 경로, API 엔드포인트, DB 연결 정보, 로그 레벨 등)을 포함하는 `config/settings.yaml` 파일의 계층적 구조와 각 설정 항목의 데이터 타입 및 기본값을 정의합니다.",
            "dependencies": [],
            "details": "`monitor`, `database`, `api`, `logging` 섹션을 포함하여 YAML 스키마를 설계합니다. 각 섹션 내의 키-값 쌍과 예상되는 데이터 형식을 명확히 문서화합니다. 예를 들어, `database.host`는 문자열, `monitor.scan_interval_minutes`는 정수 등으로 정의합니다.\n<info added on 2025-08-25T08:36:06.156Z>\nAPI 분석 결과를 반영하여 `api` 섹션의 설정 항목을 확장합니다:\n\n- `api.endpoint`: API 엔드포인트 URL (기본값: \"http://211.231.137.111:18000/upload\")\n- `api.timeout_seconds`: API 요청 타임아웃 시간 (정수, 기본값: 30)\n- `api.retry_attempts`: 재시도 횟수 (정수, 기본값: 3)\n- `api.retry_delay_seconds`: 재시도 간 지연 시간 (정수, 기본값: 5)\n- `api.max_file_size`: 최대 파일 크기 제한 (정수, 바이트 단위, 기본값: 10485760)\n- `api.allowed_extensions`: 허용된 파일 확장자 목록 (배열, 기본값: [\".txt\", \".pdf\", \".docx\", \".xlsx\"])\n\n환경별 설정 분리를 위해 `environment` 섹션을 추가하여 개발/운영 환경에 따른 설정 오버라이드를 지원합니다. API 관련 설정들은 환경 변수를 통해 오버라이드 가능하도록 설계합니다.\n</info added on 2025-08-25T08:36:06.156Z>",
            "status": "done",
            "testStrategy": "정의된 YAML 구조에 따라 `settings.yaml` 예시 파일을 작성하고, 모든 필수 설정 항목이 포함되어 있는지, 데이터 타입이 일관적인지 수동으로 검토합니다."
          },
          {
            "id": 2,
            "title": "기본 YAML 설정 로딩 기능 구현",
            "description": "`config/settings.yaml` 파일을 읽어 파싱하고 Python 딕셔너리 형태로 반환하는 핵심 로딩 함수를 구현합니다. 파일이 없거나 YAML 파싱 오류 발생 시 적절히 처리합니다.",
            "dependencies": [
              "2.1"
            ],
            "details": "`config/settings.py` 내에 `load_config` 함수를 구현하여 `PyYAML` 라이브러리의 `yaml.safe_load()`를 사용해 `settings.yaml` 파일을 로드합니다. 파일 경로를 동적으로 처리하고, `FileNotFoundError` 및 `yaml.YAMLError`를 처리하는 예외 처리 로직을 포함합니다.",
            "status": "done",
            "testStrategy": "유효한 `settings.yaml` 파일을 사용하여 설정이 올바르게 로드되는지 확인합니다. 존재하지 않는 파일 경로를 지정하거나, 문법 오류가 있는 YAML 파일을 사용하여 예외 처리가 정상적으로 작동하는지 확인합니다."
          },
          {
            "id": 3,
            "title": "환경 변수 로딩 및 설정 오버라이드 구현",
            "description": "`.env` 파일에서 환경 변수를 로드하고, 로드된 YAML 설정 중 민감 정보나 환경별로 달라지는 값을 환경 변수로 오버라이드하는 로직을 구현합니다.",
            "dependencies": [
              "2.2"
            ],
            "details": "`python-dotenv` 라이브러리의 `load_dotenv()` 함수를 사용하여 `.env` 파일의 환경 변수를 로드합니다. `os.getenv()`를 사용하여 `DB_HOST`, `API_ENDPOINT` 등 특정 환경 변수 값을 가져와 YAML 설정의 해당 필드를 덮어씁니다. 환경 변수가 없을 경우 YAML의 기본값을 유지하도록 구현합니다.",
            "status": "done",
            "testStrategy": "`.env` 파일에 `DB_HOST`와 같은 환경 변수를 설정하고, `settings.yaml`의 해당 값이 환경 변수 값으로 올바르게 오버라이드되는지 확인합니다. `.env` 파일이 없거나 특정 환경 변수가 정의되지 않았을 때 YAML의 기본값이 유지되는지 확인합니다."
          },
          {
            "id": 4,
            "title": "전역 설정 객체 및 접근 인터페이스 구현",
            "description": "최종적으로 로드되고 오버라이드된 설정을 애플리케이션 전반에서 일관되게 접근할 수 있는 전역 설정 객체 또는 인터페이스를 구현합니다. 개발/운영 환경 구분을 고려합니다.",
            "dependencies": [
              "2.3"
            ],
            "details": "`config/settings.py` 파일 내에 `CONFIG`와 같은 전역 변수를 정의하여 `load_config` 함수가 반환한 최종 설정 딕셔너리를 할당합니다. `os.getenv('APP_ENV', 'development')`를 활용하여 환경별 설정을 로드할 수 있도록 `load_config` 함수를 확장합니다. 다른 모듈에서 `from config.settings import CONFIG` 형태로 설정을 가져와 사용할 수 있도록 합니다.",
            "status": "done",
            "testStrategy": "다른 모듈에서 `CONFIG` 객체를 임포트하여 `CONFIG['database']['host']`와 같이 설정 값에 접근했을 때 올바른 값이 반환되는지 확인합니다. `APP_ENV` 환경 변수를 변경하여 다른 환경 설정이 로드되는지 테스트합니다."
          },
          {
            "id": 5,
            "title": "설정 값 유효성 검사 및 오류 처리 강화",
            "description": "로드된 설정 값의 유효성을 검사하고, 필수 설정 누락, 잘못된 데이터 타입, 유효 범위를 벗어난 값 등에 대해 적절한 오류 처리 및 로깅 기능을 추가합니다.",
            "dependencies": [
              "2.4"
            ],
            "details": "설정 로딩 후, `monitor.base_folders`가 리스트인지, `scan_interval_minutes`가 양의 정수인지 등 핵심 설정 값에 대한 유효성 검사 로직을 추가합니다. 유효하지 않은 설정이 발견되면 `ValueError`와 같은 예외를 발생시키거나 경고 로그를 남깁니다. 예를 들어, 필수 설정이 누락된 경우 시스템 시작을 중단하도록 구현합니다.",
            "status": "done",
            "testStrategy": "필수 설정 항목을 `settings.yaml`에서 제거하거나, 잘못된 데이터 타입(예: `scan_interval_minutes`에 문자열 할당), 유효 범위를 벗어난 값(예: 음수)을 설정하여 시스템이 적절한 오류 메시지와 함께 예외를 발생시키거나 경고를 로깅하는지 확인합니다."
          }
        ]
      },
      {
        "id": 3,
        "title": "로깅 시스템 구현",
        "description": "시스템의 모든 동작을 추적하고 문제 진단을 용이하게 하기 위한 로깅 시스템을 구현합니다. 다양한 로그 레벨과 파일 로테이션을 지원합니다.",
        "details": "Python의 내장 `logging` 모듈을 사용합니다. `logging.handlers.RotatingFileHandler`를 사용하여 로그 파일 크기 및 백업 개수를 관리합니다. 설정 파일(`config/settings.yaml`)에서 로그 레벨, 파일 경로, 최대 크기, 백업 개수를 읽어와 적용합니다.\n\n`utils/logger.py`:\n```python\nimport logging\nfrom logging.handlers import RotatingFileHandler\nfrom config.settings import CONFIG\n\ndef setup_logging():\n    log_config = CONFIG['logging']\n    logger = logging.getLogger('file_monitor_app')\n    logger.setLevel(getattr(logging, log_config['level'].upper()))\n\n    # 콘솔 핸들러\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))\n    logger.addHandler(console_handler)\n\n    # 파일 핸들러 (로테이션 포함)\n    file_handler = RotatingFileHandler(\n        log_config['file'],\n        maxBytes=log_config['max_bytes'],\n        backupCount=log_config['backup_count'],\n        encoding='utf-8'\n    )\n    file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n    logger.addHandler(file_handler)\n\n    return logger\n\nlogger = setup_logging()\n```\n각 모듈에서 `from utils.logger import logger`를 통해 로거 인스턴스를 사용합니다.",
        "testStrategy": "DEBUG, INFO, WARNING, ERROR, CRITICAL 레벨의 로그 메시지를 생성하여 콘솔과 로그 파일에 올바르게 기록되는지 확인합니다. 로그 파일이 설정된 크기에 도달했을 때 로테이션이 정상적으로 작동하고 백업 파일이 생성되는지 확인합니다.",
        "priority": "high",
        "dependencies": [
          1,
          2
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "기본 로거 인스턴스 및 콘솔 핸들러 설정",
            "description": "`logging` 모듈을 사용하여 기본 로거 인스턴스를 생성하고, 콘솔(표준 출력)에 로그를 출력하는 `StreamHandler`를 설정합니다. 초기 로그 레벨을 설정하고 포매터를 적용합니다.",
            "dependencies": [],
            "details": "`utils/logger.py` 파일에 `setup_logging` 함수를 정의하고, `logging.getLogger('file_monitor_app')`를 사용하여 로거를 초기화합니다. `logging.StreamHandler`를 추가하고 `logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')`를 사용하여 로그 메시지 형식을 지정합니다.",
            "status": "done",
            "testStrategy": "다양한 로그 레벨(INFO, WARNING, ERROR)의 메시지를 생성하여 콘솔에 올바른 형식으로 출력되는지 확인합니다."
          },
          {
            "id": 2,
            "title": "설정 파일 연동 및 로그 레벨 동적 설정",
            "description": "`config/settings.yaml` 파일에서 로깅 관련 설정(로그 레벨)을 읽어와 로거에 동적으로 적용합니다.",
            "dependencies": [
              "3.1"
            ],
            "details": "`config.settings.CONFIG` 객체에서 `logging['level']` 값을 가져와 `logger.setLevel(getattr(logging, log_config['level'].upper()))` 메서드에 적용합니다. 이는 Task 2의 설정 관리 시스템이 완료되어 `CONFIG` 객체를 사용할 수 있음을 전제로 합니다.",
            "status": "done",
            "testStrategy": "`settings.yaml` 파일의 `logging.level` 값을 변경해가며 로거의 실제 로그 레벨이 올바르게 변경되고, 해당 레벨 이하의 로그는 무시되는지 확인합니다."
          },
          {
            "id": 3,
            "title": "파일 로테이션 핸들러 구현",
            "description": "로그 메시지를 파일에 기록하고, 파일 크기가 일정 기준을 초과하면 자동으로 새 파일로 교체(로테이션)하며 이전 로그 파일을 백업하는 `RotatingFileHandler`를 구현합니다.",
            "dependencies": [
              "3.1",
              "3.2"
            ],
            "details": "`logging.handlers.RotatingFileHandler`를 인스턴스화하고, `log_config['file']`, `log_config['max_bytes']`, `log_config['backup_count']` 값을 사용하여 초기화합니다. 파일 핸들러에도 `logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')`를 설정하고 로거에 추가합니다.",
            "status": "done",
            "testStrategy": "`settings.yaml`에서 `max_bytes`를 작은 값으로 설정하고, 해당 크기보다 큰 로그 메시지를 반복적으로 생성하여 로그 파일이 로테이션되고 `backupCount`에 따라 백업 파일이 올바르게 생성 및 관리되는지 확인합니다."
          },
          {
            "id": 4,
            "title": "로깅 설정 통합 및 전역 로거 인스턴스 제공",
            "description": "`setup_logging` 함수를 완성하고, 애플리케이션의 다른 모듈에서 쉽게 접근할 수 있도록 전역 로거 인스턴스를 제공합니다.",
            "dependencies": [
              "3.1",
              "3.2",
              "3.3"
            ],
            "details": "`utils/logger.py` 파일 내에서 `setup_logging()` 함수를 호출하여 `logger` 변수에 할당하고, 이를 다른 모듈에서 `from utils.logger import logger` 형태로 임포트하여 사용할 수 있도록 합니다.",
            "status": "done",
            "testStrategy": "애플리케이션의 다른 모듈(예: 임시 테스트 스크립트)에서 `from utils.logger import logger`를 통해 로거를 임포트하여 INFO, ERROR 레벨의 로그를 기록하고, 콘솔과 파일에 모두 올바르게 출력되는지 확인합니다."
          },
          {
            "id": 5,
            "title": "로깅 시스템 종합 테스트 및 검증",
            "description": "구현된 로깅 시스템이 다양한 로그 레벨의 메시지를 콘솔과 파일에 올바르게 기록하고, 파일 로테이션 기능이 정상적으로 작동하는지 종합적으로 테스트하고 검증합니다.",
            "dependencies": [
              "3.1",
              "3.2",
              "3.3",
              "3.4"
            ],
            "details": "DEBUG, INFO, WARNING, ERROR, CRITICAL 레벨의 로그 메시지를 생성하는 테스트 스크립트를 작성합니다. 로그 파일이 설정된 크기에 도달했을 때 로테이션이 정상적으로 작동하고 백업 파일이 생성되는지 확인하는 시나리오를 포함합니다.",
            "status": "done",
            "testStrategy": "`utils/logger.py`를 직접 실행하거나 간단한 테스트 스크립트를 작성하여 모든 로그 레벨의 메시지가 콘솔과 로그 파일에 올바르게 기록되는지 확인합니다. 로그 파일 크기를 작게 설정하여 로테이션이 여러 번 발생하도록 유도하고, 백업 파일의 존재 여부와 내용이 올바른지 검증합니다."
          }
        ]
      },
      {
        "id": 4,
        "title": "데이터베이스 스키마 설계 및 ORM 모델 정의",
        "description": "파일 정보와 업로드 결과를 저장할 데이터베이스 스키마를 설계하고 SQLAlchemy ORM을 사용하여 모델을 정의합니다. SQLite(개발) 및 PostgreSQL(운영) 모두를 지원하도록 추상화합니다.",
        "details": "SQLAlchemy 2.0을 사용하여 `files` 및 `upload_results` 테이블을 정의합니다. `declarative_base`를 사용하여 모델 클래스를 생성합니다.\n\n`models/base.py`:\n```python\nfrom sqlalchemy.ext.declarative import declarative_base\nBase = declarative_base()\n```\n\n`models/file.py`:\n```python\nfrom sqlalchemy import Column, Integer, String, DateTime, Boolean, Enum\nfrom sqlalchemy.sql import func\nfrom models.base import Base\nimport enum\n\nclass FileStatus(enum.Enum):\n    PENDING = 'pending'\n    UPLOADED = 'uploaded'\n    FAILED = 'failed'\n\nclass File(Base):\n    __tablename__ = 'files'\n    id = Column(Integer, primary_key=True)\n    filename = Column(String, nullable=False)\n    filepath = Column(String, unique=True, nullable=False)\n    folder_name = Column(String, nullable=False)\n    file_date = Column(DateTime, nullable=False) # YYYY-MM-DD 폴더에서 추출\n    size_bytes = Column(Integer)\n    checksum = Column(String) # 파일 중복 방지용\n    status = Column(Enum(FileStatus), default=FileStatus.PENDING, nullable=False)\n    created_at = Column(DateTime, server_default=func.now())\n    updated_at = Column(DateTime, onupdate=func.now())\n\n    def __repr__(self):\n        return f'<File(filename={self.filename}, status={self.status})>'\n```\n\n`models/upload_result.py`:\n```python\nfrom sqlalchemy import Column, Integer, String, DateTime, ForeignKey\nfrom sqlalchemy.sql import func\nfrom sqlalchemy.orm import relationship\nfrom models.base import Base\n\nclass UploadResult(Base):\n    __tablename__ = 'upload_results'\n    id = Column(Integer, primary_key=True)\n    file_id = Column(Integer, ForeignKey('files.id'), nullable=False)\n    api_response_code = Column(Integer)\n    api_response_body = Column(String)\n    upload_status = Column(String, nullable=False) # SUCCESS, FAILED, RETRYING\n    attempt_count = Column(Integer, default=1)\n    uploaded_at = Column(DateTime, server_default=func.now())\n\n    file = relationship('File', backref='upload_results')\n\n    def __repr__(self):\n        return f'<UploadResult(file_id={self.file_id}, status={self.upload_status})>'\n```",
        "testStrategy": "SQLite 및 PostgreSQL 데이터베이스에 연결하여 `Base.metadata.create_all(engine)`을 실행하여 테이블이 성공적으로 생성되는지 확인합니다. 각 모델 클래스의 인스턴스를 생성하고 속성에 접근하여 데이터 타입 및 제약 조건이 올바른지 검증합니다.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Base ORM 클래스 정의",
            "description": "SQLAlchemy의 `declarative_base`를 사용하여 모든 ORM 모델의 기반이 될 `Base` 클래스를 `models/base.py` 파일에 정의합니다.",
            "dependencies": [],
            "details": "`models/base.py` 파일에 `from sqlalchemy.ext.declarative import declarative_base; Base = declarative_base()` 코드를 작성합니다.",
            "status": "done",
            "testStrategy": "`Base` 객체가 성공적으로 임포트되고 `declarative_base`의 인스턴스인지 확인하는 간단한 유닛 테스트를 수행합니다."
          },
          {
            "id": 2,
            "title": "`File` ORM 모델 정의",
            "description": "파일 정보를 저장할 `files` 테이블에 대한 `File` ORM 모델을 `models/file.py` 파일에 정의합니다. 파일명, 경로, 크기, 상태, 생성/수정일 등의 컬럼을 포함하고, `FileStatus` Enum을 활용합니다.",
            "dependencies": [
              "4.1"
            ],
            "details": "`models/file.py`에 `File` 클래스를 정의하고, `Column`, `Integer`, `String`, `DateTime`, `Boolean`, `Enum` 등의 SQLAlchemy 타입을 사용하여 컬럼을 명시합니다. `FileStatus` Enum을 정의하고 `status` 컬럼에 적용합니다.",
            "status": "done",
            "testStrategy": "`File` 모델 클래스가 성공적으로 임포트되고, `__tablename__`이 'files'로 설정되었는지 확인합니다. `FileStatus` Enum이 올바르게 정의되었는지 확인합니다."
          },
          {
            "id": 3,
            "title": "`UploadResult` ORM 모델 정의 및 관계 설정",
            "description": "파일 업로드 결과를 저장할 `upload_results` 테이블에 대한 `UploadResult` ORM 모델을 `models/upload_result.py` 파일에 정의합니다. `File` 모델과의 외래 키 관계를 설정하고, `relationship`을 사용하여 양방향 접근을 가능하게 합니다.",
            "dependencies": [
              "4.1",
              "4.2"
            ],
            "details": "`models/upload_result.py`에 `UploadResult` 클래스를 정의하고, `file_id` 컬럼에 `ForeignKey('files.id')`를 설정합니다. `file = relationship('File', backref='upload_results')`를 추가하여 관계를 정의합니다.\n<info added on 2025-08-25T08:35:51.036Z>\nAPI 스펙 분석 결과를 반영하여 UploadResult 모델을 업데이트합니다. 다음 필드들을 추가합니다:\n- api_file_id: 외부 API에서 할당된 파일 고유 식별자 (String)\n- filename: 업로드된 파일명 (String)\n- file_size: 파일 크기 (Integer)\n- upload_time: 업로드 시간 (DateTime)\n- download_url: 다운로드 URL (String)\n- view_url: 파일 보기 URL (String)\n- message: API 응답 메시지 (String)\n\napi_file_id는 외부 API에서 할당된 고유 식별자로 활용하고, download_url과 view_url은 파일 접근 경로 정보로 저장합니다. file_size와 upload_time 정보는 파일 일치성 검증에 활용하며, message 필드는 로깅에 활용할 수 있도록 합니다.\n</info added on 2025-08-25T08:35:51.036Z>",
            "status": "done",
            "testStrategy": "`UploadResult` 모델 클래스가 성공적으로 임포트되고, `__tablename__`이 'upload_results'로 설정되었는지 확인합니다. `file_id` 컬럼에 외래 키 제약 조건이 올바르게 정의되었는지 확인합니다."
          },
          {
            "id": 4,
            "title": "데이터베이스 엔진 및 스키마 생성 유틸리티 구현",
            "description": "SQLite(개발) 및 PostgreSQL(운영) 데이터베이스에 연결하기 위한 SQLAlchemy 엔진을 생성하고, 정의된 ORM 모델을 기반으로 데이터베이스 스키마를 생성하는 유틸리티 함수 또는 스크립트를 구현합니다. 이는 `Base.metadata.create_all(engine)`을 호출하는 로직을 포함합니다.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.3"
            ],
            "details": "`db/utils.py` 또는 유사한 파일에 데이터베이스 URL을 받아 SQLAlchemy 엔진을 생성하는 함수와, 해당 엔진을 사용하여 `Base.metadata.create_all()`을 호출하는 함수를 구현합니다. 설정 파일에서 DB 연결 정보를 읽어오도록 합니다.",
            "status": "done",
            "testStrategy": "SQLite 및 PostgreSQL 연결 문자열을 사용하여 엔진을 생성하고 `create_all_tables` 함수를 호출하여 테이블이 성공적으로 생성되는지 확인합니다. 기존 테이블이 있을 경우 충돌 없이 작동하는지 확인합니다."
          },
          {
            "id": 5,
            "title": "ORM 모델 및 스키마 유효성 검증 테스트 작성",
            "description": "정의된 `File` 및 `UploadResult` ORM 모델이 예상하는 데이터베이스 스키마와 일치하는지, 각 컬럼의 데이터 타입, 제약 조건(nullable, unique, default 등), 그리고 외래 키 관계가 올바르게 설정되었는지 검증하는 테스트 코드를 작성합니다.",
            "dependencies": [
              "4.4"
            ],
            "details": "`tests/test_models.py` 파일에 테스트 케이스를 작성합니다. 임시 SQLite 데이터베이스를 생성하고 `Base.metadata.create_all(engine)`을 실행한 후, 각 모델의 인스턴스를 생성하고 데이터를 저장, 조회하여 데이터 타입 및 제약 조건이 올바르게 작동하는지 검증합니다.",
            "status": "done",
            "testStrategy": "테스트 스크립트를 실행하여 모든 모델 및 스키마 유효성 검증 테스트가 성공적으로 통과하는지 확인합니다. 의도적으로 잘못된 데이터 타입을 삽입하거나 제약 조건을 위반하여 오류가 발생하는지 확인합니다."
          }
        ]
      },
      {
        "id": 5,
        "title": "데이터베이스 관리자(CRUD) 구현",
        "description": "데이터베이스 연결을 관리하고, `files` 및 `upload_results` 테이블에 대한 CRUD(생성, 읽기, 업데이트, 삭제) 작업을 수행하는 모듈을 구현합니다. 데이터 무결성 및 트랜잭션 관리를 포함합니다.",
        "details": "SQLAlchemy 엔진 및 세션 관리를 위한 `DatabaseManager` 클래스를 구현합니다. 설정 파일에서 DB 타입을 읽어와 SQLite 또는 PostgreSQL에 연결합니다. 세션 관리를 위해 컨텍스트 매니저(`with Session() as session:`)를 사용합니다.\n\n`db/manager.py`:\n```python\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\nfrom models.base import Base\nfrom config.settings import CONFIG\nfrom utils.logger import logger\n\nclass DatabaseManager:\n    def __init__(self):\n        db_config = CONFIG['database']\n        if db_config['type'] == 'sqlite':\n            self.database_url = f\"sqlite:///{db_config['sqlite_path']}\"\n        elif db_config['type'] == 'postgresql':\n            self.database_url = (\n                f\"postgresql+psycopg2://{db_config['user']}:{db_config['password']}@\"\n                f\"{db_config['host']}:{db_config['port']}/{db_config['dbname']}\"\n            )\n        else:\n            raise ValueError(\"Unsupported database type\")\n\n        self.engine = create_engine(self.database_url)\n        self.Session = sessionmaker(bind=self.engine)\n        Base.metadata.create_all(self.engine) # 테이블 생성\n        logger.info(f\"Database connected: {db_config['type']}\")\n\n    def get_session(self):\n        return self.Session()\n\n    # 예시: 파일 저장\n    def add_file(self, file_obj):\n        with self.get_session() as session:\n            session.add(file_obj)\n            session.commit()\n            session.refresh(file_obj)\n            return file_obj\n\n    # 예시: 파일 경로로 조회\n    def get_file_by_path(self, filepath):\n        with self.get_session() as session:\n            return session.query(File).filter_by(filepath=filepath).first()\n\n    # 예시: 업로드 대기 중인 파일 조회\n    def get_pending_files(self):\n        with self.get_session() as session:\n            return session.query(File).filter_by(status=FileStatus.PENDING).all()\n\n    # ... 기타 CRUD 메서드 구현\n\ndb_manager = DatabaseManager()\n```",
        "testStrategy": "SQLite 및 PostgreSQL에 연결하여 `File` 및 `UploadResult` 객체를 생성, 저장, 조회, 업데이트, 삭제하는 일련의 테스트를 수행합니다. 중복 파일 경로 저장 시 오류가 발생하는지, 트랜잭션이 올바르게 커밋/롤백되는지 확인합니다.",
        "priority": "high",
        "dependencies": [
          2,
          4
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "DatabaseManager 클래스 초기화 및 DB 연결 설정",
            "description": "DatabaseManager 클래스의 `__init__` 메서드를 완성하여 설정 파일(`config/settings.py`의 `CONFIG`)에서 데이터베이스 유형(SQLite 또는 PostgreSQL)을 읽고, 해당 데이터베이스에 대한 SQLAlchemy 엔진 및 세션 팩토리를 생성합니다. `Base.metadata.create_all()`을 호출하여 필요한 테이블이 생성되도록 합니다.",
            "dependencies": [],
            "details": "`db/manager.py` 파일 내 `DatabaseManager` 클래스의 `__init__` 메서드 구현. `create_engine` 및 `sessionmaker` 설정. `Base.metadata.create_all(self.engine)` 호출을 통해 테이블 스키마를 데이터베이스에 반영합니다.",
            "status": "done",
            "testStrategy": "DatabaseManager 인스턴스 생성 시 SQLite 및 PostgreSQL 설정에 따라 올바른 DB에 연결되고, `File` 및 `UploadResult` 테이블이 성공적으로 생성되는지 확인합니다. 잘못된 DB 타입 설정 시 `ValueError`가 발생하는지 검증합니다."
          },
          {
            "id": 2,
            "title": "`files` 테이블 CRUD(생성, 읽기, 업데이트, 삭제) 메서드 구현",
            "description": "`files` 테이블(File 모델)에 대한 기본적인 CRUD 작업을 수행하는 메서드(예: `add_file`, `get_file_by_id`, `get_file_by_path`, `update_file_status`, `delete_file`)를 `DatabaseManager` 클래스에 구현합니다.",
            "dependencies": [
              "5.1"
            ],
            "details": "`db/manager.py` 파일 내 `DatabaseManager` 클래스에 `File` 모델 관련 CRUD 메서드 추가. 각 메서드는 `with self.get_session() as session:` 패턴을 사용하여 세션을 관리하고, 변경 사항을 커밋합니다.",
            "status": "done",
            "testStrategy": "SQLite 및 PostgreSQL 환경에서 `File` 객체를 생성, 저장, ID/경로로 조회, 상태 업데이트, 삭제하는 일련의 테스트를 수행합니다. 특정 경로로 파일 조회, 상태 업데이트, 파일 삭제 후 존재 여부 등을 확인합니다."
          },
          {
            "id": 3,
            "title": "`upload_results` 테이블 CRUD(생성, 읽기, 업데이트, 삭제) 메서드 구현",
            "description": "`upload_results` 테이블(UploadResult 모델)에 대한 기본적인 CRUD 작업을 수행하는 메서드(예: `add_upload_result`, `get_upload_result_by_id`, `update_upload_result_status`, `delete_upload_result`)를 `DatabaseManager` 클래스에 구현합니다.",
            "dependencies": [
              "5.1"
            ],
            "details": "`db/manager.py` 파일 내 `DatabaseManager` 클래스에 `UploadResult` 모델 관련 CRUD 메서드 추가. 각 메서드는 `with self.get_session() as session:` 패턴을 사용하여 세션을 관리하고, 변경 사항을 커밋합니다.",
            "status": "done",
            "testStrategy": "SQLite 및 PostgreSQL 환경에서 `UploadResult` 객체를 생성, 저장, ID로 조회, 상태 업데이트, 삭제하는 일련의 테스트를 수행합니다. 특정 ID로 결과 조회, 상태 업데이트, 결과 삭제 후 존재 여부 등을 확인합니다."
          },
          {
            "id": 4,
            "title": "고급 조회 및 데이터 무결성/트랜잭션 관리 구현",
            "description": "`get_pending_files`와 같이 특정 조건에 맞는 데이터를 조회하는 고급 쿼리 메서드를 구현하고, 데이터 무결성(예: 중복 파일 경로 방지) 및 트랜잭션 관리(예: 여러 작업의 원자성 보장, 오류 발생 시 롤백) 로직을 `DatabaseManager` 내에 통합합니다.",
            "dependencies": [
              "5.2",
              "5.3"
            ],
            "details": "`db/manager.py` 파일 내 `DatabaseManager` 클래스에 `get_pending_files`, `get_files_by_status` 등 추가 조회 메서드 구현. `UniqueConstraint` 등을 활용하여 데이터 무결성을 보장하고, `try...except` 블록 내에서 `session.rollback()`을 호출하여 트랜잭션 원자성을 확보합니다.",
            "status": "done",
            "testStrategy": "업로드 대기 중인 파일 조회, 특정 상태의 파일 조회 등 복합 조건 쿼리가 올바르게 작동하는지 확인합니다. 중복 파일 경로 저장 시 오류가 발생하고 트랜잭션이 롤백되는지 확인합니다. 여러 DB 작업이 하나의 트랜잭션으로 묶여 원자적으로 처리되는지 테스트합니다."
          },
          {
            "id": 5,
            "title": "세션 컨텍스트 매니저 활용 및 예외 처리 강화",
            "description": "`DatabaseManager`의 `get_session` 메서드가 SQLAlchemy 세션의 컨텍스트 매니저 기능을 올바르게 활용하도록 보장하고, 모든 CRUD 및 조회 메서드에서 발생할 수 있는 데이터베이스 관련 예외를 적절히 처리(로깅, 롤백 등)하여 견고성을 높입니다.",
            "dependencies": [
              "5.1",
              "5.4"
            ],
            "details": "`db/manager.py` 파일 내 `DatabaseManager` 클래스의 모든 DB 접근 메서드에서 `try...except...finally` 블록을 사용하여 예외 발생 시 `session.rollback()`을 호출하고, `utils.logger`를 통해 오류를 기록하도록 구현합니다. `get_session`이 `with` 문과 함께 사용될 때 세션이 올바르게 닫히는지 확인합니다.",
            "status": "done",
            "testStrategy": "DB 작업 중 의도적으로 오류를 발생시켜 트랜잭션이 롤백되고 예외가 적절히 처리되는지 확인합니다. 세션이 `with` 블록 종료 시 올바르게 닫히는지 검증합니다. 로깅 시스템을 통해 DB 관련 오류 메시지가 정확히 기록되는지 확인합니다."
          }
        ]
      },
      {
        "id": 6,
        "title": "파일 모니터링 서비스 구현 (watchdog)",
        "description": "Python `watchdog` 라이브러리를 사용하여 지정된 폴더(`Sega_1`, `Sega_2`, `Sega_3`) 내의 오늘 날짜 폴더를 실시간으로 모니터링하고, 새로운 이미지 파일이 생성될 때 이벤트를 감지하는 서비스를 구현합니다.",
        "details": "`watchdog.observers.Observer`와 `watchdog.events.FileSystemEventHandler`를 사용합니다. `FileSystemEventHandler`를 상속받아 `on_created` 메서드를 오버라이드하여 파일 생성 이벤트를 처리합니다. 모니터링 대상 폴더는 `config/settings.yaml`에서 가져옵니다.\n\n`monitor/handler.py`:\n```python\nimport os\nfrom datetime import datetime\nfrom watchdog.events import FileSystemEventHandler\nfrom utils.logger import logger\nfrom config.settings import CONFIG\n\nclass ImageFileEventHandler(FileSystemEventHandler):\n    def __init__(self, process_file_callback):\n        super().__init__()\n        self.process_file_callback = process_file_callback\n        self.image_extensions = set(CONFIG['monitor']['image_extensions'])\n\n    def on_created(self, event):\n        if event.is_directory: # 폴더 생성 이벤트는 무시\n            return\n\n        filepath = event.src_path\n        filename = os.path.basename(filepath)\n        file_extension = os.path.splitext(filename)[1].lower()\n\n        if file_extension in self.image_extensions:\n            # 오늘 날짜 폴더에 있는지 확인 (YYYY-MM-DD)\n            today_date_str = datetime.now().strftime('%Y-%m-%d')\n            if f'/{today_date_str}/' in filepath:\n                logger.info(f\"새 이미지 파일 감지: {filepath}\")\n                self.process_file_callback(filepath)\n            else:\n                logger.debug(f\"오늘 날짜 폴더가 아닌 파일: {filepath}\")\n        else:\n            logger.debug(f\"이미지 파일이 아님: {filepath}\")\n```\n\n`monitor/service.py`:\n```python\nimport time\nimport os\nfrom datetime import datetime\nfrom watchdog.observers import Observer\nfrom config.settings import CONFIG\nfrom utils.logger import logger\nfrom monitor.handler import ImageFileEventHandler\n\nclass FileMonitorService:\n    def __init__(self, process_file_callback):\n        self.observer = Observer()\n        self.process_file_callback = process_file_callback\n        self.base_folders = CONFIG['monitor']['base_folders']\n        self.monitored_paths = set()\n\n    def _get_today_folder_path(self, base_folder):\n        today_date_str = datetime.now().strftime('%Y-%m-%d')\n        return os.path.join(base_folder, today_date_str)\n\n    def start(self):\n        event_handler = ImageFileEventHandler(self.process_file_callback)\n        for base_folder in self.base_folders:\n            today_folder = self._get_today_folder_path(base_folder)\n            if os.path.exists(today_folder) and today_folder not in self.monitored_paths:\n                logger.info(f\"모니터링 시작: {today_folder}\")\n                self.observer.schedule(event_handler, today_folder, recursive=False)\n                self.monitored_paths.add(today_folder)\n            elif not os.path.exists(today_folder):\n                logger.warning(f\"오늘 날짜 폴더가 존재하지 않습니다: {today_folder}\")\n        self.observer.start()\n        logger.info(\"파일 모니터링 서비스 시작됨.\")\n\n    def stop(self):\n        self.observer.stop()\n        self.observer.join()\n        logger.info(\"파일 모니터링 서비스 중지됨.\")\n\n    def check_and_update_monitored_folders(self):\n        # 스케줄러에 의해 주기적으로 호출되어 새로운 날짜 폴더를 모니터링 목록에 추가\n        event_handler = ImageFileEventHandler(self.process_file_callback)\n        for base_folder in self.base_folders:\n            today_folder = self._get_today_folder_path(base_folder)\n            if os.path.exists(today_folder) and today_folder not in self.monitored_paths:\n                logger.info(f\"새로운 오늘 날짜 폴더 모니터링 추가: {today_folder}\")\n                self.observer.schedule(event_handler, today_folder, recursive=False)\n                self.monitored_paths.add(today_folder)\n            elif not os.path.exists(today_folder):\n                logger.debug(f\"오늘 날짜 폴더가 아직 생성되지 않음: {today_folder}\")\n```",
        "testStrategy": "모니터링 대상 폴더에 새로운 이미지 파일(.jpg, .png)을 생성하여 `on_created` 이벤트가 올바르게 트리거되고 `process_file_callback`이 호출되는지 확인합니다. 이미지 파일이 아닌 다른 파일이나 오늘 날짜 폴더가 아닌 곳에 파일 생성 시 무시되는지 확인합니다. 모니터링 서비스 시작 및 중지 시 로그가 올바르게 기록되는지 확인합니다.",
        "priority": "high",
        "dependencies": [
          1,
          2,
          3
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "이미지 파일 이벤트 핸들러 구현",
            "description": "`watchdog.events.FileSystemEventHandler`를 상속받아 `ImageFileEventHandler` 클래스를 구현합니다. `on_created` 메서드를 오버라이드하여 새로운 파일 생성 이벤트를 감지하고, 파일 확장자가 이미지 파일(`image_extensions` 설정)이며 오늘 날짜 폴더(`YYYY-MM-DD`) 내에 있는 경우에만 `process_file_callback`을 호출하도록 로직을 구현합니다. 폴더 생성 이벤트는 무시합니다.",
            "dependencies": [],
            "details": "`monitor/handler.py` 파일에 `ImageFileEventHandler` 클래스를 정의하고, `__init__`에서 `process_file_callback`과 `image_extensions`를 초기화합니다. `on_created` 메서드 내에서 `event.is_directory` 확인, 파일 확장자 검사, 오늘 날짜 폴더 경로 포함 여부 검사를 수행합니다.",
            "status": "done",
            "testStrategy": "모의 `process_file_callback` 함수를 사용하여 `ImageFileEventHandler`를 인스턴스화합니다. 오늘 날짜 폴더에 `.jpg`, `.png` 파일을 생성하는 이벤트를 모의하여 `on_created`가 호출되고 콜백이 트리거되는지 확인합니다. 이미지 파일이 아닌 파일, 오늘 날짜 폴더가 아닌 곳에 생성된 이미지 파일, 폴더 생성 이벤트에 대해서는 콜백이 호출되지 않는지 확인합니다."
          },
          {
            "id": 2,
            "title": "파일 모니터링 서비스 초기화 및 기본 폴더 스케줄링",
            "description": "`FileMonitorService` 클래스의 `__init__` 메서드를 구현하여 `watchdog.observers.Observer` 인스턴스를 생성하고, `process_file_callback`을 저장합니다. `start` 메서드 내에서 `config/settings.yaml`에 정의된 `base_folders`를 순회하며 각 `base_folder` 내의 오늘 날짜 폴더(`YYYY-MM-DD`)를 찾아 `Observer`에 모니터링 대상으로 스케줄링합니다. 이미 존재하는 오늘 날짜 폴더만 모니터링 대상으로 추가합니다.",
            "dependencies": [
              "6.1"
            ],
            "details": "`monitor/service.py` 파일에 `FileMonitorService` 클래스를 정의합니다. `_get_today_folder_path` 헬퍼 메서드를 활용하여 오늘 날짜 폴더 경로를 생성하고, `os.path.exists`로 존재 여부를 확인합니다. `observer.schedule(event_handler, today_folder, recursive=False)`를 사용하여 모니터링을 설정합니다.",
            "status": "done",
            "testStrategy": "가상의 `base_folders`와 오늘 날짜 폴더를 생성하고, `FileMonitorService`를 초기화 및 `start` 메서드를 호출하여 `observer.schedule`이 올바른 경로로 호출되는지 확인합니다. 존재하지 않는 오늘 날짜 폴더에 대해서는 경고 로그가 기록되는지 확인합니다."
          },
          {
            "id": 3,
            "title": "주기적인 오늘 날짜 폴더 모니터링 업데이트 구현",
            "description": "`FileMonitorService` 클래스 내에 `check_and_update_monitored_folders` 메서드를 구현합니다. 이 메서드는 `base_folders`를 다시 순회하며, 아직 모니터링 목록에 추가되지 않은 새로운 오늘 날짜 폴더가 생성되었을 경우 `Observer`에 해당 폴더를 추가로 스케줄링합니다. 이 로직은 서비스가 장시간 실행될 때 자정 이후 새로운 날짜 폴더가 생성될 경우를 대비합니다.",
            "dependencies": [
              "6.1",
              "6.2"
            ],
            "details": "`monitored_paths` set을 사용하여 이미 모니터링 중인 폴더를 추적합니다. `observer.schedule`을 다시 호출하여 새로운 폴더를 추가하고 `monitored_paths`에 업데이트합니다.",
            "status": "done",
            "testStrategy": "`FileMonitorService`를 시작한 후, 모니터링 대상 `base_folder` 내에 새로운 오늘 날짜 폴더를 수동으로 생성합니다. `check_and_update_monitored_folders` 메서드를 호출하여 해당 폴더가 `observer`에 성공적으로 스케줄링되고 `monitored_paths`에 추가되는지 확인합니다."
          },
          {
            "id": 4,
            "title": "파일 모니터링 서비스 시작 및 중지 기능 구현",
            "description": "`FileMonitorService` 클래스의 `start` 메서드에서 `observer.start()`를 호출하여 모니터링 스레드를 시작하고, `stop` 메서드에서 `observer.stop()` 및 `observer.join()`을 호출하여 안전하게 모니터링 스레드를 종료하는 기능을 구현합니다. 이 두 메서드는 서비스의 전체 생명주기를 관리합니다.",
            "dependencies": [
              "6.1",
              "6.2",
              "6.3"
            ],
            "details": "`start` 메서드에서 `ImageFileEventHandler` 인스턴스를 생성하고, `base_folders`에 대한 초기 스케줄링을 완료한 후 `observer.start()`를 호출합니다. `stop` 메서드에서는 `observer.stop()`으로 이벤트를 중지하고, `observer.join()`으로 스레드가 완전히 종료될 때까지 대기합니다.",
            "status": "done",
            "testStrategy": "`FileMonitorService` 인스턴스를 생성하고 `start()`를 호출한 후, 잠시 대기하고 `stop()`을 호출하여 서비스가 정상적으로 시작되고 종료되는지 확인합니다. 시작 및 중지 시 적절한 로그 메시지가 기록되는지 확인합니다."
          },
          {
            "id": 5,
            "title": "설정 및 로깅 연동 및 서비스 통합 테스트",
            "description": "`config/settings.yaml`에서 모니터링 대상 폴더(`base_folders`) 및 이미지 확장자(`image_extensions`)를 올바르게 로드하고, `utils/logger.py`를 통해 모든 중요한 동작(서비스 시작/중지, 파일 감지, 폴더 생성 경고 등)이 로깅되도록 확인합니다. 구현된 `FileMonitorService`와 `ImageFileEventHandler`가 전체적으로 통합되어 의도한 대로 동작하는지 종합적으로 테스트합니다.",
            "dependencies": [
              "6.1",
              "6.2",
              "6.3",
              "6.4"
            ],
            "details": "`config/settings.yaml` 파일에 `monitor` 섹션을 추가하고 `base_folders`와 `image_extensions`를 정의합니다. `utils/logger.py`의 `logger` 객체를 사용하여 서비스의 각 단계에서 적절한 로그 레벨로 메시지를 기록합니다.",
            "status": "done",
            "testStrategy": "실제 모니터링 대상 폴더 구조를 설정하고, `FileMonitorService`를 실행합니다. 모니터링 대상 폴더에 새로운 이미지 파일(.jpg, .png)을 생성하여 `on_created` 이벤트가 올바르게 트리거되고 `process_file_callback`이 호출되는지 확인합니다. 이미지 파일이 아닌 다른 파일이나 오늘 날짜 폴더가 아닌 곳에 파일 생성 시 무시되는지 확인합니다. 서비스 시작 및 중지 시 로그가 올바르게 기록되는지 확인합니다. 자정 시뮬레이션을 통해 새로운 날짜 폴더가 생성되었을 때 `check_and_update_monitored_folders`가 이를 감지하고 모니터링을 시작하는지 확인합니다."
          }
        ]
      },
      {
        "id": 7,
        "title": "파일 메타데이터 추출 및 DB 저장 로직 구현",
        "description": "파일 모니터링 서비스에서 감지된 새로운 이미지 파일의 메타데이터(파일 경로, 이름, 폴더명, 날짜, 크기, 체크섬)를 추출하고, 데이터베이스에 중복 없이 저장하는 로직을 구현합니다.",
        "details": "파일 경로에서 폴더명, 파일명, 날짜 정보를 파싱합니다. `os.path.getsize`로 파일 크기를 얻고, `hashlib` 모듈을 사용하여 파일의 SHA256 체크섬을 계산하여 중복 여부를 판단합니다. 데이터베이스에 이미 존재하는 파일(동일 경로 또는 동일 체크섬)은 저장하지 않고, 상태를 업데이트합니다.\n\n`monitor/processor.py`:\n```python\nimport os\nimport hashlib\nfrom datetime import datetime\nfrom db.manager import db_manager\nfrom models.file import File, FileStatus\nfrom utils.logger import logger\n\ndef calculate_checksum(filepath, hash_algorithm='sha256'):\n    hasher = hashlib.new(hash_algorithm)\n    with open(filepath, 'rb') as f:\n        for chunk in iter(lambda: f.read(4096), b''):\n            hasher.update(chunk)\n    return hasher.hexdigest()\n\ndef process_new_file(filepath):\n    try:\n        # 1. 파일 메타데이터 추출\n        filename = os.path.basename(filepath)\n        folder_path = os.path.dirname(filepath)\n        folder_name = os.path.basename(folder_path) # YYYY-MM-DD\n        base_folder = os.path.basename(os.path.dirname(folder_path)) # Sega_X\n        file_date = datetime.strptime(folder_name, '%Y-%m-%d')\n        size_bytes = os.path.getsize(filepath)\n        checksum = calculate_checksum(filepath)\n\n        # 2. DB 중복 확인 및 저장\n        existing_file = db_manager.get_file_by_path(filepath)\n        if existing_file:\n            logger.info(f\"파일이 이미 DB에 존재합니다 (경로): {filepath}\")\n            # 필요시 상태 업데이트 로직 추가\n            return existing_file\n        \n        # 체크섬으로 중복 확인 (동일 파일이 다른 경로에 있을 경우)\n        # 이 시스템에서는 경로가 고유하므로 경로 중복만 확인해도 충분할 수 있음\n        # 하지만 견고성을 위해 체크섬도 고려\n        # existing_file_by_checksum = db_manager.get_file_by_checksum(checksum)\n        # if existing_file_by_checksum:\n        #     logger.info(f\"파일이 이미 DB에 존재합니다 (체크섬): {filepath}\")\n        #     return existing_file_by_checksum\n\n        new_file = File(\n            filename=filename,\n            filepath=filepath,\n            folder_name=base_folder, # Sega_X 폴더명 저장\n            file_date=file_date,\n            size_bytes=size_bytes,\n            checksum=checksum,\n            status=FileStatus.PENDING\n        )\n        db_manager.add_file(new_file)\n        logger.info(f\"새 파일 정보 DB에 저장 완료: {new_file.filename}\")\n        return new_file\n\n    except Exception as e:\n        logger.error(f\"파일 처리 중 오류 발생 {filepath}: {e}\", exc_info=True)\n        return None\n```",
        "testStrategy": "새로운 이미지 파일을 생성하고 `process_new_file` 함수를 호출하여 DB에 파일 정보가 올바르게 저장되는지 확인합니다. 동일한 파일을 여러 번 처리하여 중복 방지 로직이 작동하는지 확인합니다. 파일 경로, 날짜, 크기, 체크섬이 정확하게 추출되고 저장되는지 DB를 직접 조회하여 검증합니다.",
        "priority": "high",
        "dependencies": [
          2,
          5,
          6
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "파일 체크섬 계산 유틸리티 함수 구현",
            "description": "`hashlib` 모듈을 사용하여 주어진 파일의 SHA256 체크섬을 효율적으로 계산하는 `calculate_checksum` 함수를 구현합니다.",
            "dependencies": [],
            "details": "파일을 청크 단위로 읽어 메모리 사용량을 최적화하고, SHA256 알고리즘을 사용하여 체크섬을 계산합니다.",
            "status": "done",
            "testStrategy": "다양한 크기의 테스트 파일을 생성하고 `calculate_checksum` 함수를 호출하여 올바른 SHA256 체크섬이 반환되는지 확인합니다. 동일한 파일에 대해 항상 동일한 체크섬이 반환되는지 검증합니다."
          },
          {
            "id": 2,
            "title": "파일 경로 기반 메타데이터 파싱 로직 구현",
            "description": "주어진 파일 경로에서 파일명, 상위 폴더명(YYYY-MM-DD 형식), 그리고 그 상위 폴더명(예: Sega_X)을 추출하고, YYYY-MM-DD 형식의 폴더명으로부터 `datetime` 객체를 파싱하는 로직을 구현합니다.",
            "dependencies": [],
            "details": "`os.path.basename`, `os.path.dirname`, `datetime.strptime` 함수를 활용하여 파일 경로에서 필요한 정보를 추출합니다. 날짜 파싱 시 `ValueError` 발생 가능성을 고려합니다.",
            "status": "done",
            "testStrategy": "다양한 형식의 파일 경로(예: `/path/to/Sega_X/2023-01-15/image.jpg`)를 입력으로 주어 파일명, 폴더명, 날짜 정보가 정확하게 파싱되는지 확인합니다. 잘못된 날짜 형식의 폴더명에 대한 예외 처리도 테스트합니다."
          },
          {
            "id": 3,
            "title": "파일 크기 및 체크섬 추출 로직 구현",
            "description": "주어진 파일의 실제 크기(바이트 단위)를 추출하고, 구현된 `calculate_checksum` 함수를 호출하여 파일의 SHA256 체크섬을 추출하는 로직을 구현합니다.",
            "dependencies": [
              "7.1",
              "7.2"
            ],
            "details": "`os.path.getsize` 함수를 사용하여 파일 크기를 얻고, Subtask 7.1에서 구현된 `calculate_checksum` 함수를 호출하여 체크섬을 얻습니다. 파일 접근 권한 문제 등 `OSError` 발생 가능성을 고려합니다.",
            "status": "done",
            "testStrategy": "실제 파일을 생성하고 `os.path.getsize`가 정확한 크기를 반환하는지 확인합니다. Subtask 7.1의 `calculate_checksum` 함수가 올바르게 호출되고 그 결과가 사용되는지 검증합니다. 존재하지 않는 파일이나 접근 권한이 없는 파일에 대한 예외 처리도 테스트합니다."
          },
          {
            "id": 4,
            "title": "데이터베이스 중복 파일 확인 로직 구현",
            "description": "추출된 파일 경로를 사용하여 데이터베이스에 동일한 파일이 이미 존재하는지 확인하는 로직을 구현합니다. 중복 파일 발견 시, 로그를 기록하고 기존 파일 정보를 반환합니다.",
            "dependencies": [
              "7.2",
              "7.3"
            ],
            "details": "`db_manager.get_file_by_path(filepath)` 메서드를 호출하여 파일 경로 기반의 중복 여부를 판단합니다. 필요시 기존 파일의 상태를 업데이트하는 로직을 고려합니다. (체크섬 기반 중복 확인은 현재 코드에서 주석 처리되어 있으므로 경로 기반 확인에 집중합니다.)",
            "status": "done",
            "testStrategy": "새로운 파일을 처리하여 DB에 저장한 후, 동일한 파일 경로로 다시 처리하여 중복 방지 로직이 작동하는지 확인합니다. `db_manager.get_file_by_path`가 올바르게 호출되고, 중복 시 파일이 추가되지 않고 기존 파일 정보가 반환되는지 검증합니다."
          },
          {
            "id": 5,
            "title": "새로운 파일 정보 DB 저장 및 예외 처리 구현",
            "description": "추출된 모든 메타데이터를 기반으로 `File` 객체를 생성하고, 데이터베이스에 새로운 파일 정보를 추가하는 로직을 구현합니다. 전체 과정에서 발생할 수 있는 예외를 처리하고 로그를 기록합니다.",
            "dependencies": [
              "7.2",
              "7.3",
              "7.4"
            ],
            "details": "`File` 모델의 인스턴스를 생성하고 `db_manager.add_file()` 메서드를 호출합니다. `try-except` 블록을 사용하여 파일 처리 중 발생할 수 있는 `IOError`, `ValueError` (날짜 파싱 오류 등), `OSError` (파일 크기 얻기 오류 등) 및 일반적인 `Exception`을 처리하고 `logger`를 통해 상세 오류를 기록합니다.",
            "status": "done",
            "testStrategy": "중복이 아닌 새로운 파일을 처리하여 DB에 성공적으로 저장되는지 확인합니다. DB에 저장된 파일의 모든 메타데이터(파일명, 경로, 폴더명, 날짜, 크기, 체크섬, 상태)가 정확한지 직접 조회하여 검증합니다. 파일 처리 중 의도적으로 오류를 발생시켜(예: 잘못된 날짜 형식, DB 연결 끊기) 예외 처리 및 로깅이 올바르게 작동하는지 확인합니다."
          }
        ]
      },
      {
        "id": 8,
        "title": "API 클라이언트 구현 (HTTP 통신)",
        "description": "외부 API 엔드포인트(`http://211.231.137.111:18000/upload`)와 통신하기 위한 HTTP 클라이언트를 구현합니다. `requests` 라이브러리를 사용하여 파일 업로드 요청을 보내고 응답을 처리합니다. API 스펙에 따라 응답에서 file_id, download_url, view_url 등의 정보를 추출하여 반환합니다.",
        "status": "done",
        "dependencies": [
          1,
          2,
          3
        ],
        "priority": "high",
        "details": "`requests` 라이브러리를 사용하여 `POST` 요청을 보냅니다. 파일은 `multipart/form-data` 형식으로 전송합니다. API 타임아웃, 연결 오류, 응답 코드 처리 등을 포함합니다.\n\n**API 응답 스키마 (FileUploadResponse)**:\n- file_id: string (파일 고유 식별자)\n- filename: string (업로드된 파일명)\n- file_size: integer (파일 크기)\n- upload_time: date-time (업로드 시간)\n- download_url: string (다운로드 URL)\n- view_url: string (파일 보기 URL)\n- message: string (응답 메시지)\n\n`api/client.py`:\n```python\nimport os\nimport requests\nfrom config.settings import CONFIG\nfrom utils.logger import logger\n\nclass APIClient:\n    def __init__(self):\n        self.api_endpoint = CONFIG['api']['endpoint']\n        self.timeout = CONFIG['api']['timeout_seconds']\n\n    def upload_file(self, filepath):\n        try:\n            with open(filepath, 'rb') as f:\n                files = {'file': (os.path.basename(filepath), f, 'application/octet-stream')}\n                response = requests.post(\n                    self.api_endpoint,\n                    files=files,\n                    timeout=self.timeout\n                )\n                response.raise_for_status() # 200 이외의 상태 코드에 대해 예외 발생\n                \n                # JSON 응답 파싱\n                response_data = response.json()\n                logger.info(f\"파일 업로드 성공: {filepath}, file_id: {response_data.get('file_id')}, 응답 코드: {response.status_code}\")\n                return response.status_code, response_data\n        except requests.exceptions.Timeout:\n            logger.error(f\"API 요청 시간 초과: {filepath}\")\n            return 408, {\"error\": \"Timeout\"}\n        except requests.exceptions.ConnectionError:\n            logger.error(f\"API 연결 오류: {filepath}\")\n            return 503, {\"error\": \"Connection Error\"}\n        except requests.exceptions.RequestException as e:\n            logger.error(f\"API 요청 중 오류 발생 {filepath}: {e}, 응답: {getattr(e.response, 'text', 'N/A')}\")\n            return getattr(e.response, 'status_code', 500), getattr(e.response, 'text', str(e))\n        except Exception as e:\n            logger.error(f\"파일 업로드 중 예상치 못한 오류 발생 {filepath}: {e}\", exc_info=True)\n            return 500, {\"error\": str(e)}\n\napi_client = APIClient()\n```",
        "testStrategy": "실제 또는 모의(mock) API 서버를 사용하여 `upload_file` 메서드를 테스트합니다. 성공적인 업로드, 타임아웃, 연결 오류, 4xx/5xx 응답 코드 등 다양한 시나리오에 대해 올바른 상태 코드와 응답 본문을 반환하는지 확인합니다. `requests_mock` 라이브러리를 사용하여 API 응답을 모의할 수 있습니다. 특히 API 스펙에 따른 JSON 응답 구조(file_id, download_url, view_url 등)가 올바르게 파싱되고 반환되는지 검증합니다.",
        "subtasks": [
          {
            "id": 1,
            "title": "APIClient 클래스 기본 구조 및 설정 로드",
            "description": "`APIClient` 클래스를 정의하고, `config.settings`에서 API 엔드포인트와 타임아웃 설정을 로드하여 인스턴스 변수로 초기화합니다.",
            "status": "done",
            "dependencies": [],
            "details": "`__init__` 메서드를 구현하여 `self.api_endpoint`와 `self.timeout`을 `CONFIG['api']['endpoint']` 및 `CONFIG['api']['timeout_seconds']` 값으로 설정합니다.",
            "testStrategy": "`APIClient` 인스턴스를 생성하고 `api_endpoint` 및 `timeout` 속성이 `config.settings`에 정의된 값으로 올바르게 초기화되는지 확인합니다. `config.settings`가 모의(mock)된 경우에도 작동하는지 검증합니다."
          },
          {
            "id": 2,
            "title": "파일 업로드 요청 데이터 준비 및 전송",
            "description": "`upload_file` 메서드 내에서 지정된 경로의 파일을 바이너리 모드로 열고, `requests` 라이브러리의 `files` 매개변수에 적합한 `multipart/form-data` 형식으로 요청 데이터를 구성한 후, `POST` 요청을 API 엔드포인트로 전송합니다.",
            "status": "done",
            "dependencies": [
              1
            ],
            "details": "`with open(filepath, 'rb') as f:`를 사용하여 파일을 열고, `files = {'file': (os.path.basename(filepath), f, 'application/octet-stream')}` 형태로 데이터를 구성합니다. 구성된 데이터를 사용하여 `requests.post(self.api_endpoint, files=files, timeout=self.timeout)`를 호출합니다.",
            "testStrategy": "`requests_mock`과 같은 라이브러리를 사용하여 `requests.post` 호출을 모의(mock)하고, `upload_file` 메서드가 올바른 엔드포인트, 파일 데이터(`multipart/form-data`), 타임아웃 값으로 요청을 보내는지 확인합니다. 파일이 올바르게 열리고 데이터가 전달되는지 검증합니다."
          },
          {
            "id": 3,
            "title": "성공적인 HTTP 응답 처리 및 JSON 파싱",
            "description": "API 요청이 성공적으로 완료되었을 때(HTTP 2xx 상태 코드), `response.raise_for_status()`를 통해 상태 코드를 확인하고, JSON 응답을 파싱하여 file_id, download_url, view_url 등의 정보를 추출합니다. 성공 메시지와 함께 `utils.logger`를 사용하여 정보를 기록하고 응답 데이터를 반환합니다.",
            "status": "done",
            "dependencies": [
              2
            ],
            "details": "응답 객체에 대해 `response.raise_for_status()`를 호출하여 200 이외의 성공적인 상태 코드(예: 201)를 처리하고, `response.json()`을 사용하여 JSON 응답을 파싱합니다. `logger.info(f\"파일 업로드 성공: {filepath}, file_id: {response_data.get('file_id')}, 응답 코드: {response.status_code}\")`를 사용하여 성공을 기록합니다. 최종적으로 `return response.status_code, response_data`를 수행합니다.",
            "testStrategy": "`requests_mock`을 사용하여 API 스펙에 따른 JSON 응답(file_id, filename, file_size, upload_time, download_url, view_url, message 포함)을 모의하고, `upload_file` 메서드가 올바른 상태 코드와 파싱된 JSON 데이터를 반환하며, `logger.info`가 file_id와 함께 호출되는지 확인합니다."
          },
          {
            "id": 4,
            "title": "API 요청 타임아웃 및 연결 오류 예외 처리",
            "description": "`requests.exceptions.Timeout` 및 `requests.exceptions.ConnectionError` 발생 시 이를 포착하고, `utils.logger`를 사용하여 오류를 기록한 후, 적절한 HTTP 상태 코드(예: 408, 503)와 구조화된 오류 메시지를 반환합니다.",
            "status": "done",
            "dependencies": [
              2
            ],
            "details": "`try-except` 블록 내에서 `requests.exceptions.Timeout`과 `requests.exceptions.ConnectionError`를 각각 처리합니다. 각 예외 발생 시 `logger.error`를 사용하여 오류를 기록하고, `return 408, {\"error\": \"Timeout\"}` 또는 `return 503, {\"error\": \"Connection Error\"}`와 같이 적절한 상태 코드와 구조화된 오류 메시지를 반환합니다.",
            "testStrategy": "`requests_mock`을 사용하여 `requests.exceptions.Timeout` 및 `requests.exceptions.ConnectionError`를 발생시키도록 모의하고, `upload_file` 메서드가 각각 408, 503 상태 코드와 적절한 구조화된 오류 메시지를 반환하며, `logger.error`가 호출되는지 확인합니다."
          },
          {
            "id": 5,
            "title": "일반 HTTP 요청 오류 및 기타 예외 처리",
            "description": "`requests.exceptions.RequestException` (HTTP 4xx/5xx 응답 포함) 및 예상치 못한 일반 `Exception` 발생 시 이를 포착하고, `utils.logger`를 사용하여 상세 오류를 기록합니다. 가능한 경우 API 응답의 상태 코드와 텍스트를 포함하여 반환하고, 그렇지 않은 경우 기본 오류 코드와 구조화된 메시지를 제공합니다.",
            "status": "done",
            "dependencies": [
              3,
              4
            ],
            "details": "`except requests.exceptions.RequestException as e:` 블록에서 `response.raise_for_status()`에 의해 발생한 4xx/5xx 오류(422 Validation Error 포함)를 처리하고, `getattr(e.response, 'status_code', 500)` 및 `getattr(e.response, 'text', str(e))`를 사용하여 응답 정보를 반환합니다. 마지막으로 `except Exception as e:` 블록에서 모든 예상치 못한 오류를 처리하고 `logger.error`로 기록한 후 `return 500, {\"error\": str(e)}`를 반환합니다.",
            "testStrategy": "`requests_mock`을 사용하여 400 Bad Request, 422 Validation Error, 500 Internal Server Error와 같은 `requests.exceptions.RequestException`을 발생시키도록 모의하고, `upload_file` 메서드가 API 응답의 상태 코드와 텍스트를 올바르게 반환하며 `logger.error`가 호출되는지 확인합니다. 또한, 파일 경로 오류 등 예상치 못한 일반 `Exception` 발생 시에도 적절히 처리되고 로깅되는지 검증합니다."
          }
        ]
      },
      {
        "id": 9,
        "title": "파일 업로드 및 응답 처리 로직 구현",
        "description": "감지되어 DB에 저장된 파일을 외부 API를 통해 업로드하고, API 응답(상태 코드, 응답 본문)을 `upload_results` 테이블에 저장하여 업로드 상태를 추적하는 기능을 구현합니다.",
        "details": "`File` 객체를 받아 `APIClient`를 사용하여 업로드를 시도하고, 결과를 `UploadResult` 객체로 생성하여 DB에 저장합니다. 파일의 `status` 필드를 `UPLOADED` 또는 `FAILED`로 업데이트합니다.\n\n`uploader/service.py`:\n```python\nfrom db.manager import db_manager\nfrom models.file import File, FileStatus\nfrom models.upload_result import UploadResult\nfrom api.client import api_client\nfrom utils.logger import logger\n\nclass UploaderService:\n    def upload_and_record(self, file_obj: File):\n        logger.info(f\"파일 업로드 시도: {file_obj.filepath}\")\n        status_code, response_body = api_client.upload_file(file_obj.filepath)\n\n        upload_status = \"SUCCESS\" if 200 <= status_code < 300 else \"FAILED\"\n        \n        with db_manager.get_session() as session:\n            # 파일 상태 업데이트\n            file_obj.status = FileStatus.UPLOADED if upload_status == \"SUCCESS\" else FileStatus.FAILED\n            session.add(file_obj)\n\n            # 업로드 결과 기록\n            upload_result = UploadResult(\n                file_id=file_obj.id,\n                api_response_code=status_code,\n                api_response_body=response_body,\n                upload_status=upload_status\n            )\n            session.add(upload_result)\n            session.commit()\n            logger.info(f\"파일 업로드 결과 DB에 기록: {file_obj.filename}, 상태: {upload_status}\")\n            return upload_status == \"SUCCESS\"\n\nuploader_service = UploaderService()\n```",
        "testStrategy": "DB에 `PENDING` 상태의 `File` 객체를 생성하고 `upload_and_record` 메서드를 호출합니다. API 클라이언트가 성공/실패 응답을 반환하도록 모의하여 `File` 객체의 상태와 `UploadResult` 테이블에 기록된 데이터가 올바른지 확인합니다. 특히 `api_response_code`와 `api_response_body`가 정확히 저장되는지 검증합니다.",
        "priority": "high",
        "dependencies": [
          5,
          8
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "UploaderService 클래스 및 upload_and_record 메서드 기본 구조 정의",
            "description": "`uploader/service.py` 파일에 `UploaderService` 클래스를 정의하고, `File` 객체를 인자로 받는 `upload_and_record` 메서드의 기본 틀을 구현합니다. 초기 로깅 메시지를 포함하여 파일 업로드 시도를 기록합니다.",
            "dependencies": [],
            "details": "`UploaderService` 클래스 정의, `upload_and_record(self, file_obj: File)` 메서드 시그니처 구현, `logger.info(f\"파일 업로드 시도: {file_obj.filepath}\")` 추가.",
            "status": "done",
            "testStrategy": "`upload_and_record` 메서드를 호출했을 때 초기 로깅 메시지가 올바르게 출력되는지 확인합니다. `File` 객체가 유효한지 확인합니다."
          },
          {
            "id": 2,
            "title": "외부 API를 통한 파일 업로드 및 응답 수신 로직 구현",
            "description": "`api_client`를 사용하여 `file_obj.filepath`에 지정된 파일을 외부 API로 업로드하고, API 호출의 결과로 반환되는 상태 코드와 응답 본문을 수신하는 로직을 구현합니다.",
            "dependencies": [
              "9.1"
            ],
            "details": "`status_code, response_body = api_client.upload_file(file_obj.filepath)` 코드를 `upload_and_record` 메서드 내에 구현합니다. `api_client`가 올바르게 임포트되었는지 확인합니다.",
            "status": "done",
            "testStrategy": "모의(mock) `api_client`를 사용하여 성공 및 실패 응답을 시뮬레이션하고, `upload_and_record` 메서드가 `status_code`와 `response_body`를 올바르게 수신하는지 확인합니다."
          },
          {
            "id": 3,
            "title": "API 응답 기반 업로드 성공/실패 상태 결정 로직 구현",
            "description": "수신된 API 상태 코드(`status_code`)를 분석하여 파일 업로드의 최종 성공 또는 실패 여부를 결정하는 로직을 구현합니다. 일반적으로 200번대 상태 코드를 성공으로 간주합니다.",
            "dependencies": [
              "9.2"
            ],
            "details": "`upload_status = \"SUCCESS\" if 200 <= status_code < 300 else \"FAILED\"` 로직을 구현합니다.\n<info added on 2025-08-25T08:34:50.446Z>\nAPI 응답 구조(FileUploadResponse)를 기반으로 상태 결정 로직을 확장합니다. 기존 HTTP 상태 코드 검증에 추가하여 응답 본문에서 file_id, download_url, view_url 등 필수 필드의 존재 여부를 확인합니다. 200번대 상태 코드이면서 file_id가 유효한 값으로 존재할 때만 \"SUCCESS\"로 판정하고, 그 외의 경우(422 Validation Error, 필수 필드 누락, 빈 file_id 등)는 \"FAILED\"로 처리합니다. 추출된 file_id, filename, file_size, upload_time, download_url, view_url, message 정보는 딕셔너리 형태로 반환하여 후속 DB 저장 작업에서 활용할 수 있도록 구성합니다. 응답의 message 필드는 성공/실패 여부와 관계없이 로깅 목적으로 기록합니다.\n</info added on 2025-08-25T08:34:50.446Z>",
            "status": "done",
            "testStrategy": "다양한 `status_code` (예: 200, 201, 400, 500)를 모의하여 `upload_status` 변수가 예상대로 'SUCCESS' 또는 'FAILED'로 설정되는지 확인합니다."
          },
          {
            "id": 4,
            "title": "파일 객체 상태 업데이트 및 DB 반영 로직 구현",
            "description": "결정된 `upload_status`에 따라 `file_obj`의 `status` 필드를 `FileStatus.UPLOADED` 또는 `FileStatus.FAILED`로 업데이트하고, 이 변경사항을 데이터베이스에 반영하는 로직을 구현합니다. 이 작업은 DB 트랜잭션 내에서 이루어져야 합니다.",
            "dependencies": [
              "9.3"
            ],
            "details": "`with db_manager.get_session() as session:` 블록 내에서 `file_obj.status = FileStatus.UPLOADED if upload_status == \"SUCCESS\" else FileStatus.FAILED` 및 `session.add(file_obj)`를 구현합니다.",
            "status": "done",
            "testStrategy": "DB에 `PENDING` 상태의 `File` 객체를 생성하고, `upload_status`를 모의하여 `upload_and_record` 호출 후 `File` 객체의 `status` 필드가 DB에 올바르게 업데이트되었는지 확인합니다."
          },
          {
            "id": 5,
            "title": "업로드 결과(UploadResult) 객체 생성 및 DB 저장 로직 구현",
            "description": "업로드된 파일의 ID, API 응답 코드, 응답 본문, 최종 업로드 상태를 포함하는 `UploadResult` 객체를 생성하고, 이를 `upload_results` 테이블에 저장합니다. 이 작업은 파일 객체 상태 업데이트와 동일한 DB 트랜잭션 내에서 커밋되어야 하며, 최종 로깅 및 성공 여부 반환을 포함합니다.",
            "dependencies": [
              "9.4"
            ],
            "details": "`UploadResult` 객체 생성 (`file_id`, `api_response_code`, `api_response_body`, `upload_status` 포함), `session.add(upload_result)`, `session.commit()`, 최종 로깅 (`logger.info(...)`), 그리고 `return upload_status == \"SUCCESS\"`를 구현합니다.\n<info added on 2025-08-25T08:35:01.618Z>\nAPI 응답 구조 분석 결과를 반영하여 UploadResult 객체 생성 로직을 확장합니다. API 응답에서 file_id, filename, file_size, upload_time, download_url, view_url, message 필드를 추출하여 DB에 저장합니다. file_id는 외부 API에서 할당된 고유 식별자로 활용하고, download_url과 view_url은 파일 접근 경로 정보로 저장합니다. file_size와 upload_time 정보를 검증하여 로컬 파일 정보와 일치성을 확인하고, 응답의 message 필드를 로깅에 활용합니다. 422 Validation Error 등 API 에러 응답에 대한 예외 처리도 포함합니다.\n</info added on 2025-08-25T08:35:01.618Z>",
            "status": "done",
            "testStrategy": "DB에 `PENDING` 상태의 `File` 객체를 생성하고, `api_client`를 모의하여 `upload_and_record` 호출 후 `upload_results` 테이블에 새로운 `UploadResult` 레코드가 정확한 `file_id`, `api_response_code`, `api_response_body`, `upload_status` 값으로 저장되었는지 확인합니다. 메서드의 반환 값이 올바른지 검증합니다."
          }
        ]
      },
      {
        "id": 10,
        "title": "API 업로드 에러 처리 및 재시도 메커니즘 구현",
        "description": "네트워크 오류, API 응답 실패 등 업로드 과정에서 발생할 수 있는 오류에 대비하여 자동 재시도 메커니즘을 구현합니다. 설정 파일에서 재시도 횟수와 지연 시간을 관리합니다.",
        "details": "`uploader/service.py`의 `upload_and_record` 메서드에 재시도 로직을 추가합니다. `requests` 라이브러리의 `Retry` 기능을 직접 사용하거나, 간단한 `for` 루프와 `time.sleep`을 사용하여 구현할 수 있습니다. `UploadResult` 테이블에 `attempt_count`를 기록하여 재시도 횟수를 추적합니다.\n\n`uploader/service.py` (수정):\n```python\nimport time\n# ... (기존 import)\n\nclass UploaderService:\n    def __init__(self):\n        self.max_retries = CONFIG['api']['retry_attempts']\n        self.retry_delay = CONFIG['api']['retry_delay_seconds']\n\n    def upload_and_record(self, file_obj: File):\n        attempt = 0\n        while attempt < self.max_retries:\n            attempt += 1\n            logger.info(f\"파일 업로드 시도 ({attempt}/{self.max_retries}): {file_obj.filepath}\")\n            status_code, response_body = api_client.upload_file(file_obj.filepath)\n\n            upload_status = \"SUCCESS\" if 200 <= status_code < 300 else \"FAILED\"\n            \n            with db_manager.get_session() as session:\n                # 기존 업로드 결과가 있다면 업데이트, 없다면 새로 생성\n                upload_result = session.query(UploadResult).filter_by(file_id=file_obj.id).order_by(UploadResult.uploaded_at.desc()).first()\n                if not upload_result:\n                    upload_result = UploadResult(file_id=file_obj.id)\n                \n                upload_result.api_response_code = status_code\n                upload_result.api_response_body = response_body\n                upload_result.upload_status = upload_status\n                upload_result.attempt_count = attempt\n                upload_result.uploaded_at = func.now()\n                session.add(upload_result)\n\n                if upload_status == \"SUCCESS\":\n                    file_obj.status = FileStatus.UPLOADED\n                    session.add(file_obj)\n                    session.commit()\n                    logger.info(f\"파일 업로드 성공: {file_obj.filename}, 상태: {upload_status}\")\n                    return True\n                else:\n                    file_obj.status = FileStatus.FAILED # 최종 실패 시 FAILED로 설정\n                    session.add(file_obj)\n                    session.commit()\n                    logger.warning(f\"파일 업로드 실패 ({attempt}/{self.max_retries}): {file_obj.filename}, 응답 코드: {status_code}\")\n                    if attempt < self.max_retries:\n                        logger.info(f\"재시도 대기 중 ({self.retry_delay}초): {file_obj.filename}\")\n                        time.sleep(self.retry_delay)\n                    else:\n                        logger.error(f\"최대 재시도 횟수 초과, 파일 업로드 최종 실패: {file_obj.filename}\")\n                        return False\n\n        return False\n```",
        "testStrategy": "API 클라이언트가 특정 횟수만큼 실패 응답을 반환하도록 모의하고, 재시도 로직이 설정된 횟수만큼 작동하는지 확인합니다. 재시도 간 지연 시간이 올바르게 적용되는지 확인합니다. 최종 성공 또는 최종 실패 시 `File` 및 `UploadResult` 테이블의 상태가 올바르게 업데이트되는지 검증합니다.",
        "priority": "medium",
        "dependencies": [
          2,
          9
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "재시도 관련 설정 파라미터 정의 및 UploaderService 초기화",
            "description": "`config/settings.yaml` 파일에 API 업로드 재시도 횟수(`api.retry_attempts`)와 재시도 간 지연 시간(`api.retry_delay_seconds`)을 정의합니다. `uploader/service.py`의 `UploaderService` 클래스 `__init__` 메서드에서 이 설정 값들을 로드하여 `self.max_retries`와 `self.retry_delay` 멤버 변수를 초기화합니다.",
            "dependencies": [],
            "details": "`settings.yaml` 파일에 `api` 섹션 아래 `retry_attempts` (기본값 3) 및 `retry_delay_seconds` (기본값 5)를 추가합니다. `UploaderService` 생성자에서 `CONFIG` 객체를 통해 이 값들을 가져와 멤버 변수를 초기화합니다.",
            "status": "done",
            "testStrategy": "`settings.yaml` 파일에 다양한 재시도 설정 값을 정의하고, `UploaderService` 인스턴스가 생성될 때 이 값들이 올바르게 로드되는지 확인하는 단위 테스트를 작성합니다."
          },
          {
            "id": 2,
            "title": "`upload_and_record` 메서드에 재시도 루프 및 기본 API 호출 로직 구현",
            "description": "`uploader/service.py`의 `upload_and_record` 메서드 내부에 `while` 루프를 사용하여 API 업로드 시도를 반복하는 기본 재시도 로직을 구현합니다. 각 시도마다 `attempt` 카운터를 증가시키고, `api_client.upload_file`을 호출하여 업로드 결과를 받습니다.",
            "dependencies": [
              "10.1"
            ],
            "details": "`attempt = 0`으로 초기화하고 `while attempt < self.max_retries:` 루프를 시작합니다. 루프 내에서 `attempt += 1`을 수행하고 `api_client.upload_file(file_obj.filepath)`를 호출하여 `status_code`와 `response_body`를 받도록 합니다.",
            "status": "done",
            "testStrategy": "`api_client.upload_file`을 모의(mock)하여 특정 횟수만큼 실패 응답을 반환하도록 설정하고, `upload_and_record` 메서드가 `self.max_retries`에 설정된 횟수만큼 `api_client.upload_file`을 호출하는지 확인하는 단위 테스트를 작성합니다."
          },
          {
            "id": 3,
            "title": "각 재시도 시도별 `UploadResult` 및 `File` 상태 업데이트",
            "description": "`upload_and_record` 메서드 내에서 각 업로드 시도(성공 또는 실패) 후, `UploadResult` 테이블에 해당 시도의 `api_response_code`, `api_response_body`, `upload_status`, `attempt_count`, `uploaded_at` 정보를 기록하거나 업데이트합니다. 또한, 업로드 성공 시 `File` 객체의 `status`를 `FileStatus.UPLOADED`로, 실패 시 `FileStatus.FAILED`로 즉시 업데이트합니다.",
            "dependencies": [
              "10.2"
            ],
            "details": "`db_manager.get_session()`을 사용하여 세션을 얻고, `UploadResult`를 조회하거나 새로 생성하여 필드를 업데이트합니다. `file_obj.status`를 적절히 변경하고 `session.add(file_obj)` 및 `session.commit()`을 수행합니다.\n<info added on 2025-08-25T08:35:20.858Z>\nAPI 응답 구조에 따라 각 재시도 시도 후 FileUploadResponse에서 file_id, filename, file_size, upload_time, download_url, view_url, message 필드를 추출하여 UploadResult 테이블에 저장합니다. 성공 시에는 file_id를 외래키로 설정하고 download_url, view_url을 별도 필드에 기록하며, file_size와 upload_time의 일치성을 검증합니다. API 응답의 message 필드는 로깅에 활용하고, 422 Validation Error 등의 에러 응답 시에는 상세한 오류 정보를 api_response_body에 JSON 형태로 저장합니다. 재시도 간에도 응답 정보의 일관성을 유지하여 최종 성공 시 완전한 FileUploadResponse 데이터가 보존되도록 합니다.\n</info added on 2025-08-25T08:35:20.858Z>",
            "status": "done",
            "testStrategy": "모의 DB 세션을 사용하여 `upload_and_record`가 호출될 때 `UploadResult`와 `File` 객체의 상태가 각 시도마다 올바르게 기록되고 업데이트되는지 확인하는 통합 테스트를 작성합니다. 특히, `attempt_count`가 정확히 증가하는지 검증합니다."
          },
          {
            "id": 4,
            "title": "재시도 간 지연 및 최종 업로드 결과 반환 로직 구현",
            "description": "업로드 시도가 실패하고 아직 최대 재시도 횟수에 도달하지 않았다면, `self.retry_delay`에 설정된 시간만큼 `time.sleep`을 사용하여 다음 재시도까지 대기합니다. 업로드가 성공하면 즉시 `True`를 반환하고, 모든 재시도에도 불구하고 최종적으로 실패하면 `False`를 반환하도록 `upload_and_record` 메서드의 흐름을 완성합니다.",
            "dependencies": [
              "10.2",
              "10.3"
            ],
            "details": "`if upload_status == \"SUCCESS\": return True` 로직을 구현합니다. `else` 블록 내에서 `if attempt < self.max_retries: time.sleep(self.retry_delay)` 로직을 추가하고, 루프 종료 후 `return False`를 추가합니다.",
            "status": "done",
            "testStrategy": "`time.sleep`을 모의(mock)하여 실제 지연 없이 테스트를 실행하고, 재시도 간 지연 로직이 올바르게 호출되는지 확인합니다. API 클라이언트가 특정 횟수 실패 후 성공하거나, 계속 실패할 때 `upload_and_record`의 최종 반환 값이 올바른지 검증합니다."
          },
          {
            "id": 5,
            "title": "재시도 과정 상세 로깅 및 네트워크 예외 처리 강화",
            "description": "업로드 시도 시작, 각 시도 번호, 재시도 대기, 성공, 최종 실패 등 재시도 메커니즘의 모든 주요 단계에 대한 상세한 로그 메시지를 `logger`를 사용하여 기록합니다. 또한, `api_client.upload_file` 호출 시 발생할 수 있는 `requests` 라이브러리의 네트워크 관련 예외(예: `requests.exceptions.ConnectionError`, `requests.exceptions.Timeout`)를 `try-except` 블록으로 명시적으로 처리하여 재시도 로직이 이러한 예외 상황에서도 견고하게 작동하도록 합니다.",
            "dependencies": [
              "10.2",
              "10.3",
              "10.4"
            ],
            "details": "`logger.info`, `logger.warning`, `logger.error`를 사용하여 코드 스니펫에 제시된 로깅 메시지를 구현합니다. `api_client.upload_file` 호출을 `try-except requests.exceptions.RequestException as e:` 블록으로 감싸고, 예외 발생 시 `upload_status`를 `FAILED`로 설정하고 재시도 로직을 따르도록 합니다.",
            "status": "done",
            "testStrategy": "API 클라이언트가 `requests.exceptions.ConnectionError`와 같은 네트워크 예외를 발생시키도록 모의하고, `upload_and_record` 메서드가 이 예외를 적절히 처리하고 재시도를 수행하며, 관련 로그 메시지를 정확히 기록하는지 확인하는 통합 테스트를 작성합니다."
          }
        ]
      },
      {
        "id": 11,
        "title": "1분 주기 스케줄러 구현 및 핵심 로직 통합",
        "description": "1분 주기로 시스템의 핵심 로직(새로운 날짜 폴더 확인, DB에 저장된 `PENDING` 상태 파일 업로드 시도)을 실행하는 스케줄러를 구현합니다. `APScheduler` 라이브러리를 활용합니다.",
        "details": "`APScheduler.schedulers.background.BackgroundScheduler`를 사용하여 백그라운드에서 작업을 실행합니다. 두 가지 주요 작업을 스케줄링합니다:\n1.  `FileMonitorService.check_and_update_monitored_folders`: 매분마다 호출하여 새로운 날짜 폴더가 생성되었는지 확인하고 모니터링 목록에 추가합니다.\n2.  `process_pending_uploads`: DB에서 `PENDING` 상태의 파일을 조회하여 `UploaderService`를 통해 업로드를 시도합니다.\n\n`main.py` (일부):\n```python\nfrom apscheduler.schedulers.background import BackgroundScheduler\nfrom monitor.service import FileMonitorService\nfrom monitor.processor import process_new_file\nfrom uploader.service import uploader_service\nfrom db.manager import db_manager\nfrom models.file import FileStatus\nfrom utils.logger import logger\nfrom config.settings import CONFIG\nimport time\n\ndef process_pending_uploads():\n    logger.info(\"업로드 대기 중인 파일 확인 및 처리 시작...\")\n    pending_files = db_manager.get_pending_files()\n    if not pending_files:\n        logger.info(\"업로드 대기 중인 파일 없음.\")\n        return\n\n    for file_obj in pending_files:\n        logger.info(f\"업로드 대기 중인 파일 처리: {file_obj.filename}\")\n        uploader_service.upload_and_record(file_obj)\n\ndef main():\n    logger.info(\"시스템 시작 중...\")\n    \n    # 파일 모니터링 서비스 초기화\n    file_monitor = FileMonitorService(process_new_file)\n    file_monitor.start() # 초기 모니터링 시작\n\n    # 스케줄러 설정\n    scheduler = BackgroundScheduler()\n    scan_interval = CONFIG['monitor']['scan_interval_minutes']\n    \n    # 1. 새로운 날짜 폴더 확인 및 모니터링 목록 업데이트\n    scheduler.add_job(file_monitor.check_and_update_monitored_folders, 'interval', minutes=scan_interval, id='update_monitored_folders')\n    \n    # 2. 업로드 대기 중인 파일 처리\n    scheduler.add_job(process_pending_uploads, 'interval', minutes=scan_interval, id='process_uploads')\n    \n    scheduler.start()\n    logger.info(f\"스케줄러 시작됨. {scan_interval}분마다 작업 실행.\")\n\n    try:\n        while True:\n            time.sleep(2) # 메인 스레드 유지\n    except (KeyboardInterrupt, SystemExit):\n        file_monitor.stop()\n        scheduler.shutdown()\n        logger.info(\"시스템 종료됨.\")\n\nif __name__ == '__main__':\n    main()\n```",
        "testStrategy": "스케줄러를 실행하고 로그를 통해 `update_monitored_folders` 및 `process_pending_uploads` 작업이 1분 주기로 올바르게 트리거되는지 확인합니다. `PENDING` 상태의 파일을 DB에 삽입하여 스케줄러가 이를 감지하고 업로드를 시도하는지 확인합니다. 새로운 날짜 폴더를 수동으로 생성하여 `check_and_update_monitored_folders`가 이를 모니터링 목록에 추가하는지 확인합니다.",
        "priority": "high",
        "dependencies": [
          2,
          6,
          7,
          10
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "APScheduler 초기화 및 기본 설정",
            "description": "`APScheduler.schedulers.background.BackgroundScheduler` 인스턴스를 생성하고, 스케줄링 간격(`scan_interval_minutes`)을 설정 파일에서 로드할 준비를 합니다.",
            "dependencies": [],
            "details": "`BackgroundScheduler` 객체를 생성하고, `config/settings.py`를 통해 로드된 `CONFIG['monitor']['scan_interval_minutes']` 값을 스케줄링 간격으로 사용할 수 있도록 준비합니다.",
            "status": "done",
            "testStrategy": "`main.py`를 실행하여 `BackgroundScheduler` 객체가 성공적으로 생성되고, `scan_interval` 값이 `CONFIG`에서 올바르게 로드되는지 확인합니다. 초기화 관련 로그를 검토합니다."
          },
          {
            "id": 2,
            "title": "`FileMonitorService` 초기화 및 첫 번째 스케줄링 작업 추가",
            "description": "`FileMonitorService` 인스턴스를 생성하고, `file_monitor.check_and_update_monitored_folders` 메서드를 1분 주기(또는 설정된 `scan_interval`)로 실행하도록 스케줄러에 등록합니다.",
            "dependencies": [
              "11.1"
            ],
            "details": "`FileMonitorService(process_new_file)`를 호출하여 서비스 인스턴스를 생성하고, `scheduler.add_job`을 사용하여 `file_monitor.check_and_update_monitored_folders`를 `interval` 트리거와 `scan_interval` 주기로 스케줄링합니다. 작업 ID는 'update_monitored_folders'로 지정합니다.",
            "status": "done",
            "testStrategy": "스케줄러를 실행하고 로그를 통해 'update_monitored_folders' 작업이 설정된 주기로 올바르게 트리거되는지 확인합니다. 새로운 날짜 폴더를 수동으로 생성하여 `check_and_update_monitored_folders`가 이를 감지하고 모니터링 목록에 추가하는지 확인합니다."
          },
          {
            "id": 3,
            "title": "`process_pending_uploads` 함수 구현",
            "description": "데이터베이스에서 `PENDING` 상태의 파일을 조회하고, 각 파일에 대해 `UploaderService.upload_and_record`를 호출하여 업로드를 시도하는 `process_pending_uploads` 함수를 구현합니다.",
            "dependencies": [],
            "details": "`db_manager.get_pending_files()`를 사용하여 `PENDING` 상태의 파일 목록을 가져옵니다. 목록의 각 파일 객체에 대해 `uploader_service.upload_and_record(file_obj)`를 호출하여 업로드 로직을 실행합니다. 로깅을 통해 처리 과정을 명확히 합니다.",
            "status": "done",
            "testStrategy": "테스트용 DB에 `PENDING` 상태의 파일을 삽입한 후 `process_pending_uploads` 함수를 직접 호출하여 파일이 `UPLOADED` 또는 `FAILED` 상태로 올바르게 변경되고, `UploaderService`가 호출되는지 확인합니다. 로그를 통해 업로드 시도 및 결과 메시지를 검증합니다."
          },
          {
            "id": 4,
            "title": "`process_pending_uploads` 스케줄링 작업 추가",
            "description": "구현된 `process_pending_uploads` 함수를 1분 주기(또는 설정된 `scan_interval`)로 실행하도록 스케줄러에 등록합니다.",
            "dependencies": [
              "11.1",
              "11.3"
            ],
            "details": "`scheduler.add_job`을 사용하여 `process_pending_uploads` 함수를 `interval` 트리거와 `scan_interval` 주기로 스케줄링합니다. 작업 ID는 'process_uploads'로 지정합니다.",
            "status": "done",
            "testStrategy": "스케줄러를 실행하고 로그를 통해 'process_uploads' 작업이 설정된 주기로 올바르게 트리거되는지 확인합니다. `PENDING` 상태의 파일을 DB에 삽입하여 스케줄러가 이를 감지하고 업로드를 시도하는지 확인합니다."
          },
          {
            "id": 5,
            "title": "스케줄러 시작, 메인 스레드 유지 및 안전 종료 로직 통합",
            "description": "`APScheduler`를 시작하고, 메인 스레드가 종료되지 않도록 `time.sleep` 루프를 구현하며, 시스템 종료 시 스케줄러와 모니터링 서비스를 안전하게 종료하는 로직을 통합합니다.",
            "dependencies": [
              "11.1",
              "11.2"
            ],
            "details": "`scheduler.start()`를 호출하여 스케줄러 작업을 시작합니다. `while True: time.sleep(2)` 루프를 사용하여 메인 스레드를 유지하고, `try-except (KeyboardInterrupt, SystemExit)` 블록 내에서 `file_monitor.stop()` 및 `scheduler.shutdown()`을 호출하여 시스템을 안전하게 종료합니다.",
            "status": "done",
            "testStrategy": "시스템을 시작하고 스케줄러가 정상 작동하는지 확인합니다. `Ctrl+C`를 눌러 시스템을 종료할 때 `file_monitor.stop()` 및 `scheduler.shutdown()`이 호출되고 로그에 '시스템 종료됨' 메시지가 출력되는지 확인합니다. 스케줄러 종료 후 더 이상 작업이 실행되지 않는지 검증합니다."
          }
        ]
      },
      {
        "id": 12,
        "title": "Systemd 서비스를 통한 백그라운드 자동 실행 설정",
        "description": "Ubuntu 시스템에서 스케줄러 및 파일 모니터링 서비스가 시스템 시작 시 자동으로 실행되고, 백그라운드에서 안정적으로 동작하도록 `systemd` 서비스를 설정합니다.",
        "details": "프로젝트 루트에 `file_monitor.service` 파일을 생성하고 `/etc/systemd/system/` 경로에 배포합니다. Python 가상 환경을 활성화하고 `main.py`를 실행하도록 설정합니다.\n\n`/etc/systemd/system/file_monitor.service`:\n```ini\n[Unit]\nDescription=File Monitoring and Auto-Upload Service\nAfter=network.target\n\n[Service]\nUser=your_username # 서비스 실행 사용자\nGroup=your_group # 서비스 실행 그룹\nWorkingDirectory=/path/to/your/project # 프로젝트 루트 경로\nExecStart=/path/to/your/project/venv/bin/python /path/to/your/project/main.py\nRestart=always\nRestartSec=5\nStandardOutput=journal\nStandardError=journal\n\n[Install]\nWantedBy=multi-user.target\n```\n\n설치 및 활성화 명령:\n```bash\nsudo cp /path/to/your/project/file_monitor.service /etc/systemd/system/\nsudo systemctl daemon-reload\nsudo systemctl enable file_monitor.service\nsudo systemctl start file_monitor.service\n```\n로그 확인:\n```bash\nsudo journalctl -u file_monitor.service -f\n```",
        "testStrategy": "서비스 파일을 배포하고 `systemctl start` 명령으로 서비스를 시작하여 백그라운드에서 정상적으로 실행되는지 확인합니다. 시스템 재부팅 후 서비스가 자동으로 시작되는지 확인합니다. `systemctl status` 및 `journalctl` 명령으로 서비스 상태와 로그를 모니터링하여 오류가 없는지 검증합니다. 서비스 강제 종료 후 `Restart=always` 설정에 따라 자동으로 재시작되는지 확인합니다.",
        "priority": "high",
        "dependencies": [
          11
        ],
        "status": "in-progress",
        "subtasks": [
          {
            "id": 1,
            "title": "`file_monitor.service` 파일 생성 및 사용자/경로 설정",
            "description": "`systemd` 서비스 정의 파일인 `file_monitor.service`를 프로젝트 루트에 생성하고, 서비스 실행에 필요한 `User`, `Group`, `WorkingDirectory`, `ExecStart` 경로를 실제 환경에 맞게 정확히 설정합니다.",
            "dependencies": [],
            "details": "제공된 템플릿을 사용하여 `file_monitor.service` 파일을 생성합니다. `your_username`을 실제 시스템 사용자 이름으로, `your_group`을 해당 사용자의 기본 그룹 또는 적절한 그룹으로 대체합니다. `/path/to/your/project`를 프로젝트의 실제 절대 경로로, `ExecStart` 경로를 Python 가상 환경 내 `python` 실행 파일과 `main.py`의 실제 절대 경로로 수정합니다.",
            "status": "done",
            "testStrategy": "생성된 `file_monitor.service` 파일의 내용이 올바른 사용자, 그룹, 작업 디렉토리, 실행 경로를 포함하는지 수동으로 검토합니다. 특히 `ExecStart` 경로가 Python 가상 환경의 `python`과 `main.py`를 정확히 가리키는지 확인합니다."
          },
          {
            "id": 2,
            "title": "`systemd` 서비스 파일 배포",
            "description": "생성된 `file_monitor.service` 파일을 `systemd`가 서비스를 인식하고 관리할 수 있는 표준 시스템 경로인 `/etc/systemd/system/`으로 복사합니다.",
            "dependencies": [
              "12.1"
            ],
            "details": "`sudo cp /path/to/your/project/file_monitor.service /etc/systemd/system/` 명령어를 사용하여 `file_monitor.service` 파일을 지정된 경로로 복사합니다.",
            "status": "done",
            "testStrategy": "`ls /etc/systemd/system/file_monitor.service` 명령을 실행하여 파일이 성공적으로 복사되었는지 확인합니다. 파일의 권한이 `systemd`가 읽을 수 있도록 적절하게 설정되었는지 확인합니다."
          },
          {
            "id": 3,
            "title": "`systemd` 데몬 재로드 및 서비스 활성화",
            "description": "`systemd` 데몬을 재로드하여 새로 배포된 서비스 파일을 인식하게 하고, 시스템 부팅 시 `file_monitor.service`가 자동으로 시작되도록 활성화합니다.",
            "dependencies": [
              "12.2"
            ],
            "details": "`sudo systemctl daemon-reload` 명령을 실행하여 `systemd` 설정 변경 사항을 적용합니다. 이어서 `sudo systemctl enable file_monitor.service` 명령을 실행하여 서비스의 자동 시작을 설정합니다.",
            "status": "done",
            "testStrategy": "`sudo systemctl is-enabled file_monitor.service` 명령을 실행하여 서비스가 'enabled' 상태로 올바르게 활성화되었는지 확인합니다."
          },
          {
            "id": 4,
            "title": "`systemd` 서비스 수동 시작 및 초기 동작 확인",
            "description": "`file_monitor.service`를 즉시 수동으로 시작하여 서비스가 백그라운드에서 정상적으로 실행되는지 확인하고, 초기 로그를 통해 오류 여부를 검토합니다.",
            "dependencies": [
              "12.3"
            ],
            "details": "`sudo systemctl start file_monitor.service` 명령을 실행하여 서비스를 시작합니다. 서비스 시작 직후 `sudo systemctl status file_monitor.service` 명령으로 서비스의 현재 상태(Active: active (running))를 확인합니다.",
            "status": "done",
            "testStrategy": "`sudo systemctl status file_monitor.service` 명령으로 서비스가 'active (running)' 상태인지 확인합니다. `sudo journalctl -u file_monitor.service --since \"1 minute ago\"` 명령으로 최근 로그를 확인하여 서비스 시작 시 오류 메시지가 없는지 검증합니다."
          },
          {
            "id": 5,
            "title": "서비스 자동 재시작 및 시스템 부팅 시 자동 실행 검증",
            "description": "`Restart=always` 설정이 올바르게 작동하는지 확인하기 위해 서비스를 강제 종료한 후 자동으로 재시작되는지 검증합니다. 또한, 시스템 재부팅 후 서비스가 자동으로 시작되는지 최종적으로 확인합니다.",
            "dependencies": [
              "12.4"
            ],
            "details": "`sudo systemctl stop file_monitor.service` 명령으로 서비스를 강제 종료합니다. `RestartSec=5` 설정에 따라 5초 후 서비스가 자동으로 재시작되는지 `sudo systemctl status file_monitor.service` 명령으로 확인합니다. 마지막으로, 시스템을 재부팅한 후 `sudo systemctl status file_monitor.service` 및 `sudo journalctl -u file_monitor.service` 명령을 통해 서비스가 자동으로 시작되고 정상적으로 동작하는지 확인합니다.",
            "status": "in-progress",
            "testStrategy": "서비스를 수동으로 중지한 후, 지정된 `RestartSec` 시간 내에 서비스가 자동으로 'active (running)' 상태로 전환되는지 `systemctl status`로 확인합니다. 시스템을 재부팅한 후, 로그인하여 `systemctl status file_monitor.service` 명령으로 서비스가 자동으로 시작되었는지 확인하고, `journalctl -u file_monitor.service`로 재부팅 이후의 로그를 검토하여 오류가 없는지 최종 검증합니다."
          }
        ]
      },
      {
        "id": 13,
        "title": "포괄적인 에러 처리 및 시스템 복원력 강화",
        "description": "파일 시스템 권한 문제, 네트워크 불안정, 데이터베이스 연결 오류 등 다양한 예외 상황에 대한 포괄적인 에러 처리 로직을 구현하고, 시스템의 복원력을 강화합니다.",
        "details": "각 모듈(파일 모니터링, DB 관리, API 클라이언트)에서 발생할 수 있는 특정 예외를 식별하고, `try-except` 블록을 사용하여 적절하게 처리합니다. 중요한 오류는 `logger.error`로 기록하고, 필요한 경우 재시도 로직을 트리거하거나 시스템 관리자에게 알림을 보낼 수 있도록 확장성을 고려합니다.\n\n- **파일 시스템 권한**: `os.access()`를 사용하여 파일 접근 권한을 사전 확인하거나, `PermissionError` 예외를 처리합니다.\n- **네트워크 안정성**: `requests.exceptions`의 다양한 예외(Timeout, ConnectionError 등)를 `APIClient`에서 처리하고, 재시도 로직을 활용합니다.\n- **데이터베이스 연결 오류**: `SQLAlchemy`의 `OperationalError` 등을 `DatabaseManager`에서 처리하고, 연결 재시도 로직을 구현합니다. (예: `sqlalchemy.exc.OperationalError` 발생 시 일정 시간 대기 후 엔진 재연결 시도).\n- **파일 손상/읽기 오류**: `IOError` 또는 `FileNotFoundError`를 처리하여 파일 처리 중단 없이 다음 파일로 넘어갈 수 있도록 합니다.\n\n`db/manager.py` (연결 재시도 예시):\n```python\n# ... (기존 코드)\nimport time\nfrom sqlalchemy.exc import OperationalError\n\nclass DatabaseManager:\n    # ... (기존 __init__)\n\n    def _connect_with_retry(self, max_retries=5, delay=5):\n        for i in range(max_retries):\n            try:\n                engine = create_engine(self.database_url)\n                engine.connect() # 연결 테스트\n                logger.info(f\"Database connection successful after {i} retries.\")\n                return engine\n            except OperationalError as e:\n                logger.error(f\"Database connection failed (attempt {i+1}/{max_retries}): {e}\")\n                if i < max_retries - 1:\n                    time.sleep(delay)\n        raise ConnectionError(\"Failed to connect to database after multiple retries.\")\n\n    def __init__(self):\n        # ... (기존 db_config 설정)\n        self.engine = self._connect_with_retry()\n        self.Session = sessionmaker(bind=self.engine)\n        Base.metadata.create_all(self.engine)\n        logger.info(f\"Database connected: {db_config['type']}\")\n```",
        "testStrategy": "파일 시스템 권한을 의도적으로 제한하거나, 네트워크 연결을 끊거나, DB 서버를 일시적으로 중단시키는 등 다양한 오류 상황을 시뮬레이션하여 시스템이 적절하게 반응하고 오류를 기록하며, 가능한 경우 복구 또는 재시도를 수행하는지 확인합니다. `journalctl` 로그를 통해 에러 메시지가 명확하게 기록되는지 검증합니다.",
        "priority": "medium",
        "dependencies": [
          3,
          5,
          6,
          8
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "파일 시스템 관련 에러 처리 로직 구현",
            "description": "`FileMonitorService` 및 `ImageFileEventHandler` 모듈에서 발생할 수 있는 파일 시스템 관련 예외(예: `PermissionError`, `IOError`, `FileNotFoundError`)를 처리하는 로직을 구현합니다.",
            "dependencies": [],
            "details": "`os.access()`를 사용하여 파일 접근 권한을 사전 확인하고, `try-except` 블록을 활용하여 해당 예외들을 적절히 처리합니다. 중요한 오류는 `logger.error`로 기록하고, 파일 처리 중단 없이 다음 파일로 넘어갈 수 있도록 합니다.",
            "status": "pending",
            "testStrategy": "특정 파일/디렉토리에 대한 권한을 의도적으로 제한하거나, 존재하지 않는 파일에 접근을 시도하여 `PermissionError`, `FileNotFoundError` 등이 올바르게 처리되고 로그에 기록되는지 확인합니다."
          },
          {
            "id": 2,
            "title": "API 클라이언트 네트워크 에러 처리 및 재시도 로직 구현",
            "description": "`APIClient` 모듈에서 발생할 수 있는 네트워크 관련 예외(예: `requests.exceptions.Timeout`, `ConnectionError`)를 처리하고, 일시적인 네트워크 불안정 상황에 대비한 재시도 로직을 구현합니다.",
            "dependencies": [],
            "details": "`requests.exceptions`의 다양한 예외를 `try-except` 블록으로 처리하고, 설정 가능한 최대 재시도 횟수와 지연 시간을 가진 재시도 메커니즘을 구현합니다. 모든 실패는 `logger.error`로 기록합니다.",
            "status": "pending",
            "testStrategy": "네트워크 연결을 일시적으로 끊거나, 응답이 지연되는 모의 API 서버를 사용하여 `ConnectionError`, `Timeout` 등의 예외가 발생했을 때 재시도 로직이 올바르게 작동하고 최종 실패 시 적절히 로그에 기록되는지 확인합니다."
          },
          {
            "id": 3,
            "title": "데이터베이스 연결 및 쿼리 에러 처리 로직 구현",
            "description": "`DatabaseManager` 모듈에서 발생할 수 있는 데이터베이스 연결 오류(예: `sqlalchemy.exc.OperationalError`) 및 쿼리 실행 중 발생할 수 있는 예외를 처리하고, 연결 재시도 로직을 구현합니다.",
            "dependencies": [],
            "details": "제공된 예시 코드(`_connect_with_retry`)를 참조하여 `DatabaseManager` 초기화 시 데이터베이스 연결 재시도 로직을 구현합니다. 쿼리 실행 중 발생할 수 있는 다른 `SQLAlchemy` 예외들도 `try-except` 블록으로 처리하고 `logger.error`로 기록합니다.",
            "status": "pending",
            "testStrategy": "데이터베이스 서버를 일시적으로 중단시키거나 연결 정보를 잘못 설정하여 `OperationalError`가 발생했을 때 재시도 로직이 작동하는지, 그리고 최종 실패 시 적절히 로그에 기록되는지 확인합니다. 잘못된 쿼리 실행 시 발생하는 예외 처리도 검증합니다."
          },
          {
            "id": 4,
            "title": "에러 로깅 표준화 및 시스템 관리자 알림 확장성 확보",
            "description": "시스템 전반에 걸쳐 에러 로깅 방식을 표준화하고, 중요한 에러 발생 시 시스템 관리자에게 알림을 보낼 수 있는 확장 가능한 구조를 마련합니다.",
            "dependencies": [
              "13.1",
              "13.2",
              "13.3"
            ],
            "details": "모든 에러 처리 로직에서 `logger.error`를 일관되게 사용하여 상세한 에러 메시지와 스택 트레이스를 기록하도록 합니다. 향후 이 로그를 기반으로 이메일, Slack 메시지 등 외부 알림 시스템과 연동할 수 있도록 알림 트리거 포인트를 고려하여 설계합니다.",
            "status": "pending",
            "testStrategy": "각 모듈에서 의도적으로 에러를 발생시켜 `logger.error`가 올바른 형식과 내용으로 로그 파일에 기록되는지 `journalctl` 또는 로그 파일을 직접 확인하여 검증합니다. 알림 확장성을 위한 코드 구조가 명확한지 코드 리뷰를 통해 확인합니다."
          },
          {
            "id": 5,
            "title": "포괄적인 에러 처리 및 시스템 복원력 기능 통합 테스트",
            "description": "구현된 파일 시스템, 네트워크, 데이터베이스 에러 처리 및 재시도 로직이 시스템 전체 워크플로우 내에서 올바르게 작동하는지 통합적으로 테스트하고 검증합니다.",
            "dependencies": [
              "13.1",
              "13.2",
              "13.3",
              "13.4"
            ],
            "details": "파일 시스템 권한 제한, 네트워크 연결 단절, 데이터베이스 서버 중단 등 다양한 복합적인 오류 상황을 시뮬레이션하여 시스템이 예외를 적절히 처리하고, 가능한 경우 복구 또는 재시도를 수행하며, 중요한 오류를 정확히 기록하는지 확인합니다. `Task 14`의 테스트 전략을 활용하여 테스트 케이스를 작성합니다.",
            "status": "pending",
            "testStrategy": "`Task 13`의 `Test Strategy`에 명시된 대로 파일 시스템 권한 제한, 네트워크 연결 끊기, DB 서버 일시 중단 등의 시나리오를 직접 구현하여 시스템의 반응을 관찰합니다. `journalctl` 로그를 분석하여 에러 메시지가 명확하고 일관되게 기록되는지, 재시도 로직이 예상대로 작동하는지 검증합니다."
          }
        ]
      },
      {
        "id": 14,
        "title": "단위 및 통합 테스트, 성능 최적화",
        "description": "시스템의 핵심 기능(파일 감지, DB 저장, API 업로드, 스케줄링)에 대한 단위 테스트 및 통합 테스트를 작성합니다. 성능 병목 현상을 식별하고 최적화 방안을 모색합니다.",
        "details": "Python의 `unittest` 또는 `pytest` 프레임워크를 사용하여 테스트 코드를 작성합니다. 각 모듈의 함수와 클래스 메서드에 대한 단위 테스트를 작성하고, 모듈 간의 상호작용을 검증하는 통합 테스트를 작성합니다.\n\n- **단위 테스트**: `FileMonitorService`, `ImageFileEventHandler`, `APIClient`, `DatabaseManager`의 각 메서드에 대해 독립적으로 테스트합니다. `unittest.mock`을 사용하여 외부 의존성(파일 시스템, 네트워크, DB)을 모의합니다.\n- **통합 테스트**: 전체 워크플로우(파일 생성 -> 감지 -> DB 저장 -> 업로드 -> 결과 기록)를 테스트합니다. 실제 DB와 모의 API를 사용하여 테스트할 수 있습니다.\n- **성능 테스트**: 대량의 파일을 동시에 생성하거나, 네트워크 지연이 심한 환경을 시뮬레이션하여 시스템의 처리량과 응답 시간을 측정합니다. `cProfile`과 같은 Python 프로파일링 도구를 사용하여 병목 현상을 식별합니다.\n\n`tests/test_monitor.py` 예시:\n```python\nimport unittest\nfrom unittest.mock import MagicMock, patch\nimport os\nimport tempfile\nfrom datetime import datetime\nfrom monitor.handler import ImageFileEventHandler\nfrom monitor.processor import process_new_file\n\nclass TestFileMonitor(unittest.TestCase):\n    def setUp(self):\n        self.temp_dir = tempfile.mkdtemp()\n        today_folder = datetime.now().strftime('%Y-%m-%d')\n        self.monitor_path = os.path.join(self.temp_dir, today_folder)\n        os.makedirs(self.monitor_path)\n        \n        self.mock_process_file_callback = MagicMock()\n        self.handler = ImageFileEventHandler(self.mock_process_file_callback)\n\n    def tearDown(self):\n        import shutil\n        shutil.rmtree(self.temp_dir)\n\n    def test_on_created_image_file(self):\n        test_file_path = os.path.join(self.monitor_path, 'test_image.jpg')\n        with open(test_file_path, 'w') as f:\n            f.write('dummy content')\n        \n        event = MagicMock()\n        event.is_directory = False\n        event.src_path = test_file_path\n        \n        self.handler.on_created(event)\n        self.mock_process_file_callback.assert_called_once_with(test_file_path)\n\n    @patch('db.manager.db_manager.add_file')\n    @patch('db.manager.db_manager.get_file_by_path')\n    @patch('monitor.processor.calculate_checksum', return_value='dummy_checksum')\n    def test_process_new_file_success(self, mock_checksum, mock_get_file, mock_add_file):\n        mock_get_file.return_value = None # 파일이 DB에 없다고 가정\n        test_file_path = os.path.join(self.monitor_path, 'new_image.png')\n        with open(test_file_path, 'w') as f:\n            f.write('dummy content')\n        \n        result = process_new_file(test_file_path)\n        self.assertIsNotNone(result)\n        mock_add_file.assert_called_once()\n        self.assertEqual(result.filename, 'new_image.png')\n\nif __name__ == '__main__':\n    unittest.main()\n```",
        "testStrategy": "모든 단위 테스트 및 통합 테스트가 성공적으로 통과하는지 확인합니다. `pytest`를 실행하여 테스트 커버리지를 측정하고, 주요 코드 경로가 테스트되었는지 확인합니다. 프로파일링 도구를 사용하여 성능 병목 현상을 식별하고, 개선 후 성능 지표가 향상되었는지 재측정합니다.",
        "priority": "medium",
        "dependencies": [
          11,
          13
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "핵심 모듈 단위 테스트 작성 (파일 모니터링 및 이벤트 처리)",
            "description": "`FileMonitorService` 및 `ImageFileEventHandler` 모듈의 각 메서드에 대한 단위 테스트를 작성합니다. 파일 시스템 이벤트 감지, 파일 경로 처리, 콜백 호출 등의 로직을 독립적으로 검증합니다.",
            "dependencies": [],
            "details": "Python의 `unittest` 또는 `pytest` 프레임워크를 사용합니다. `unittest.mock`을 활용하여 파일 시스템 접근, 외부 콜백 함수 등 외부 의존성을 모의(mock) 처리합니다. `tests/test_monitor.py` 예시 코드를 참고하여 `ImageFileEventHandler`의 `on_created` 메서드 및 관련 파일 처리 로직을 테스트합니다.",
            "status": "pending",
            "testStrategy": "작성된 단위 테스트를 실행하여 모든 테스트 케이스가 성공적으로 통과하는지 확인합니다. 특히 모의 객체가 예상대로 호출되고 동작하는지 검증합니다."
          },
          {
            "id": 2,
            "title": "핵심 모듈 단위 테스트 작성 (DB 관리 및 API 통신)",
            "description": "`DatabaseManager` 및 `APIClient` 모듈의 각 메서드에 대한 단위 테스트를 작성합니다. 데이터베이스 CRUD 작업, API 요청 및 응답 처리, 오류 처리 로직 등을 독립적으로 검증합니다.",
            "dependencies": [],
            "details": "Python의 `unittest` 또는 `pytest` 프레임워크를 사용합니다. `unittest.mock`을 활용하여 실제 데이터베이스 연결, 네트워크 요청 등 외부 의존성을 모의 처리합니다. `DatabaseManager`의 파일 정보 저장/조회/업데이트 메서드와 `APIClient`의 파일 업로드/상태 업데이트 메서드를 중점적으로 테스트합니다.",
            "status": "pending",
            "testStrategy": "작성된 단위 테스트를 실행하여 모든 테스트 케이스가 성공적으로 통과하는지 확인합니다. 모의 객체를 통해 DB 및 API 호출이 올바른 인자로 이루어지는지 검증합니다."
          },
          {
            "id": 3,
            "title": "시스템 통합 테스트 작성 및 실행",
            "description": "파일 생성부터 감지, DB 저장, API 업로드, 결과 기록에 이르는 전체 시스템 워크플로우에 대한 통합 테스트를 작성합니다. 각 모듈 간의 상호작용과 데이터 흐름이 올바른지 검증합니다.",
            "dependencies": [
              "14.1",
              "14.2"
            ],
            "details": "실제 데이터베이스(개발용 또는 인메모리 DB)를 사용하고, API 클라이언트는 모의(mock) API 서버 또는 `unittest.mock`을 사용하여 외부 API 의존성을 처리합니다. 파일 시스템 모니터링이 실제 파일을 감지하고, 이어서 DB 저장 및 모의 API 업로드까지의 전체 과정을 시뮬레이션하는 시나리오를 구성합니다.",
            "status": "pending",
            "testStrategy": "통합 테스트를 실행하여 전체 워크플로우가 예상대로 동작하고, 각 단계에서 데이터가 올바르게 처리되며, 최종 결과가 정확한지 확인합니다. 테스트 후 DB 상태를 검증합니다."
          },
          {
            "id": 4,
            "title": "초기 성능 프로파일링 및 병목 현상 식별",
            "description": "시스템의 주요 기능(파일 처리, DB 작업, API 통신)에 대한 초기 성능 테스트를 수행하고, `cProfile`과 같은 프로파일링 도구를 사용하여 성능 병목 현상을 식별합니다.",
            "dependencies": [
              "14.3"
            ],
            "details": "대량의 파일을 동시에 생성하거나, 네트워크 지연이 심한 환경을 시뮬레이션하는 테스트 시나리오를 구성합니다. Python의 `cProfile` 또는 `line_profiler`와 같은 도구를 사용하여 CPU 사용 시간, 함수 호출 횟수 등을 측정하고, 처리량(throughput) 및 응답 시간(response time)과 같은 성능 지표를 기록합니다.",
            "status": "pending",
            "testStrategy": "다양한 부하 조건에서 성능 테스트를 여러 번 실행하고, 프로파일링 보고서를 분석하여 가장 많은 시간을 소비하는 코드 섹션이나 함수 호출을 식별합니다. 초기 성능 지표를 문서화합니다."
          },
          {
            "id": 5,
            "title": "성능 최적화 적용 및 개선 검증",
            "description": "이전 단계에서 식별된 성능 병목 현상을 해결하기 위한 최적화 방안을 모색하고 적용합니다. 최적화 후 성능 테스트를 재실행하여 개선 효과를 검증하고 결과를 문서화합니다.",
            "dependencies": [
              "14.4"
            ],
            "details": "병목 현상에 따라 데이터베이스 쿼리 최적화, 비동기 처리 도입, 캐싱 전략 적용, I/O 작업 효율화 등 적절한 최적화 기법을 적용합니다. 최적화된 코드를 배포한 후, Subtask 4와 동일한 성능 테스트 시나리오를 사용하여 시스템의 처리량과 응답 시간을 재측정합니다.",
            "status": "pending",
            "testStrategy": "최적화된 시스템에서 성능 테스트를 재실행하고, 이전 단계의 성능 지표와 비교하여 개선 효과를 정량적으로 검증합니다. 성능 향상 여부와 최적화 방안에 대한 상세 보고서를 작성합니다."
          }
        ]
      },
      {
        "id": 15,
        "title": "Ubuntu 배포 스크립트 및 운영 모니터링 도구 구현",
        "description": "Ubuntu 시스템에 서비스를 배포하기 위한 스크립트를 작성하고, 운영 환경에서 시스템 상태를 모니터링하고 문제를 진단할 수 있는 도구를 마련합니다.",
        "details": "배포 스크립트는 다음 단계를 자동화합니다:\n1.  Git 리포지토리 클론 또는 업데이트\n2.  Python 가상 환경 생성 및 의존성 설치 (`pip install -r requirements.txt`)\n3.  설정 파일(`settings.yaml`, `.env`) 배포 및 권한 설정\n4.  `systemd` 서비스 파일(`file_monitor.service`) 복사 및 활성화 (`systemctl daemon-reload`, `systemctl enable`, `systemctl start`)\n5.  필요한 디렉토리(로그, 데이터) 생성 및 권한 설정\n\n모니터링 및 알림 시스템은 다음과 같이 구성할 수 있습니다:\n-   **로그 분석**: `journalctl`을 사용하여 시스템 로그를 실시간으로 모니터링하고, `grep` 또는 `awk`와 같은 도구를 사용하여 특정 오류 패턴을 검색합니다.\n-   **상태 확인 스크립트**: 서비스가 실행 중인지, DB 연결이 정상인지, 모니터링 폴더가 존재하는지 등을 확인하는 간단한 쉘 스크립트를 작성합니다.\n-   **알림**: 중요한 오류(CRITICAL 레벨 로그) 발생 시 Slack, 이메일 또는 다른 알림 시스템으로 메시지를 전송하는 기능을 `utils/logger.py`에 추가할 수 있습니다. (예: `logging.handlers.SMTPHandler` 또는 커스텀 핸들러).\n\n`deploy.sh` 예시:\n```bash\n#!/bin/bash\n\nPROJECT_DIR=\"/opt/file_monitor_app\"\nSERVICE_NAME=\"file_monitor.service\"\n\n# 1. 프로젝트 디렉토리 생성 및 권한 설정\nsudo mkdir -p $PROJECT_DIR\nsudo chown -R your_username:your_group $PROJECT_DIR\n\n# 2. Git 클론 또는 업데이트\n# cd $PROJECT_DIR && git pull || git clone https://github.com/your/repo.git .\n\n# 3. 가상 환경 설정 및 의존성 설치\npython3.9 -m venv $PROJECT_DIR/venv\nsource $PROJECT_DIR/venv/bin/activate\npip install -r $PROJECT_DIR/requirements.txt\ndeactivate\n\n# 4. 설정 파일 배포 (수동 또는 자동화)\n# cp config/settings.yaml $PROJECT_DIR/config/\n# cp .env $PROJECT_DIR/\n\n# 5. systemd 서비스 파일 배포 및 활성화\nsudo cp $PROJECT_DIR/$SERVICE_NAME /etc/systemd/system/\nsudo systemctl daemon-reload\nsudo systemctl enable $SERVICE_NAME\nsudo systemctl restart $SERVICE_NAME\n\necho \"Deployment complete. Check service status with: sudo systemctl status $SERVICE_NAME\"\n```",
        "testStrategy": "배포 스크립트를 실행하여 시스템이 Ubuntu 환경에 성공적으로 배포되고 서비스가 시작되는지 확인합니다. `systemctl status` 및 `journalctl`을 사용하여 서비스 상태와 로그를 모니터링합니다. 의도적으로 오류를 발생시켜 알림 시스템이 정상적으로 작동하는지 확인합니다. 상태 확인 스크립트를 실행하여 시스템의 주요 구성 요소가 올바르게 작동하는지 검증합니다.",
        "priority": "medium",
        "dependencies": [
          12,
          14
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "배포 스크립트 초기 구조 및 권한 설정 구현",
            "description": "`deploy.sh` 스크립트의 기본 구조를 마련하고, 프로젝트 디렉토리 생성, 권한 설정 및 Git 리포지토리 클론/업데이트 로직을 구현합니다.",
            "dependencies": [],
            "details": "`PROJECT_DIR` 정의, `sudo mkdir -p $PROJECT_DIR`, `sudo chown -R your_username:your_group $PROJECT_DIR`, `git pull` 또는 `git clone` 로직을 포함합니다.",
            "status": "pending",
            "testStrategy": "스크립트를 실행하여 프로젝트 디렉토리가 올바른 권한으로 생성되고, Git 리포지토리가 성공적으로 클론 또는 업데이트되는지 확인합니다."
          },
          {
            "id": 2,
            "title": "Python 가상 환경 및 애플리케이션 의존성 배포 자동화",
            "description": "배포 스크립트에 Python 가상 환경 생성 및 활성화, `requirements.txt`에 명시된 의존성 라이브러리 설치 로직을 추가합니다.",
            "dependencies": [
              "15.1"
            ],
            "details": "`python3.9 -m venv $PROJECT_DIR/venv`, `source $PROJECT_DIR/venv/bin/activate`, `pip install -r $PROJECT_DIR/requirements.txt`, `deactivate` 명령을 포함합니다.",
            "status": "pending",
            "testStrategy": "스크립트를 실행하여 가상 환경이 생성되고 `requirements.txt`의 모든 의존성이 오류 없이 설치되는지 확인합니다. `pip freeze` 명령으로 설치된 패키지 목록을 검증합니다."
          },
          {
            "id": 3,
            "title": "설정 파일 및 Systemd 서비스 배포 및 활성화",
            "description": "`settings.yaml`, `.env`와 같은 설정 파일을 배포하고, `file_monitor.service` 파일을 `/etc/systemd/system/` 경로에 복사한 후 `systemctl` 명령을 사용하여 서비스를 활성화하고 시작하는 로직을 구현합니다.",
            "dependencies": [
              "15.1",
              "15.2"
            ],
            "details": "설정 파일 복사 (예: `cp config/settings.yaml $PROJECT_DIR/config/`), `sudo cp $PROJECT_DIR/$SERVICE_NAME /etc/systemd/system/`, `sudo systemctl daemon-reload`, `sudo systemctl enable $SERVICE_NAME`, `sudo systemctl restart $SERVICE_NAME` 명령을 포함합니다.",
            "status": "pending",
            "testStrategy": "스크립트를 실행하여 설정 파일이 올바른 위치에 배포되고, `systemd` 서비스가 성공적으로 등록 및 시작되는지 확인합니다. `systemctl status file_monitor.service` 명령으로 서비스 상태를 검증합니다."
          },
          {
            "id": 4,
            "title": "운영 환경 상태 모니터링 스크립트 개발",
            "description": "서비스의 실행 상태, DB 연결 여부, 필수 디렉토리 존재 여부 등을 확인하는 쉘 스크립트를 작성하고, `journalctl`과 `grep`/`awk`를 활용하여 시스템 로그에서 특정 오류 패턴을 검색하는 기능을 구현합니다.",
            "dependencies": [
              "15.3"
            ],
            "details": "`check_status.sh` 스크립트 작성 (예: `systemctl is-active`, `pg_isready`, `ls -d`), `monitor_logs.sh` 스크립트 작성 (예: `journalctl -u file_monitor.service -f | grep \"ERROR\"`)을 포함합니다.",
            "status": "pending",
            "testStrategy": "개발된 모니터링 스크립트를 실행하여 서비스 상태, DB 연결, 필수 디렉토리 존재 여부가 정확하게 보고되는지 확인합니다. 의도적으로 오류를 발생시켜 로그 분석 스크립트가 해당 오류 패턴을 감지하는지 확인합니다."
          },
          {
            "id": 5,
            "title": "CRITICAL 로그 기반 알림 시스템 통합",
            "description": "`utils/logger.py`에 CRITICAL 레벨 로그 발생 시 Slack, 이메일 또는 기타 알림 시스템으로 메시지를 전송하는 기능을 추가합니다.",
            "dependencies": [
              "15.4"
            ],
            "details": "`logging.handlers.SMTPHandler` 또는 커스텀 핸들러를 사용하여 알림 로직을 구현합니다. `settings.yaml` 또는 `.env`에서 알림 관련 설정(예: Slack 웹훅 URL, SMTP 서버 정보)을 로드하도록 연동합니다.",
            "status": "pending",
            "testStrategy": "CRITICAL 레벨의 로그를 의도적으로 발생시켜 Slack 또는 이메일로 알림 메시지가 정상적으로 전송되는지 확인합니다. 알림 메시지의 내용과 형식이 올바른지 검증합니다."
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-08-25T08:22:12.571Z",
      "updated": "2025-08-25T12:31:58.672Z",
      "description": "Tasks for master context"
    }
  }
}